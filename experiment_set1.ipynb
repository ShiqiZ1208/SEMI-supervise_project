{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOi/HQ7LVV7Rczea7jmlR6C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShiqiZ1208/SEMI-supervise_project/blob/main/experiment_set1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0pX5Uln84k2",
        "outputId": "368a0377-db36-45d4-c27b-07db437b16db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAnpcAM_9Pf3",
        "outputId": "1cb99db7-3d36-4d62-d9ce-d9ab6dfc8dbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ShiqiZ1208/SEMI-supervise_project.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VEssgF-9IAn",
        "outputId": "b539fb2d-fc12-443b-f26b-5c329c13c62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SEMI-supervise_project'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 78 (delta 36), reused 55 (delta 16), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (78/78), 2.67 MiB | 17.07 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/SEMI-supervise_project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46FUzfPt9XsH",
        "outputId": "b421879f-bf27-471a-ae43-ba736c041e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SEMI-supervise_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirement.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxARbmL-97nZ",
        "outputId": "bd1a725d-101c-49d0-bd6b-7c723b5b73c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirement.txt (line 1)) (4.57.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from -r requirement.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from -r requirement.txt (line 3)) (4.0.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from -r requirement.txt (line 4)) (0.36.0)\n",
            "Collecting evaluate (from -r requirement.txt (line 5))\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting rouge_score (from -r requirement.txt (line 6))\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirement.txt (line 1)) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirement.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirement.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirement.txt (line 1)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirement.txt (line 1)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirement.txt (line 1)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirement.txt (line 1)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirement.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirement.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate->-r requirement.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate->-r requirement.txt (line 2)) (2.9.0+cu126)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirement.txt (line 3)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirement.txt (line 3)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirement.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirement.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->-r requirement.txt (line 3)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirement.txt (line 3)) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r requirement.txt (line 4)) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r requirement.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score->-r requirement.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score->-r requirement.txt (line 6)) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score->-r requirement.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirement.txt (line 3)) (3.13.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirement.txt (line 1)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirement.txt (line 1)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirement.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirement.txt (line 1)) (2025.11.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score->-r requirement.txt (line 6)) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score->-r requirement.txt (line 6)) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->-r requirement.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->-r requirement.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->-r requirement.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirement.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirement.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirement.txt (line 3)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirement.txt (line 3)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirement.txt (line 3)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirement.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r requirement.txt (line 3)) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate->-r requirement.txt (line 2)) (3.0.3)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=3f7fe9dcb4c44c644480e58a83e33530e57f501df0f6275dc12ed63b13eedf46\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score, evaluate\n",
            "Successfully installed evaluate-0.4.6 rouge_score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -o train -b 8 -e 6 -save true -l false -mode GAN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ-Oj0H59a2t",
        "outputId": "b027129d-02f8-472c-d3e8-bb5f5e70613f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-01 21:44:31.355672: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764625471.375967   71056 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764625471.382182   71056 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764625471.397843   71056 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764625471.397870   71056 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764625471.397873   71056 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764625471.397875   71056 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "train_GAN\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\n",
            "=============================================fine tuning==================================\n",
            "\n",
            "Num_Epochs:10, Batch_size:8\n",
            "  0% 0/920 [00:00<?, ?it/s]\n",
            "  0% 0/103 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch:0    | Batch:0    | Gtrain_loss:0.0000| Dtrain_loss:0.6250|0.7736\n",
            "\n",
            " discrimnator prediction: 70.63%| 22.66%\n",
            "  2% 20/920 [03:19<2:30:04, 10.00s/it]\n",
            "Epoch:0    | Batch:20   | Gtrain_loss:0.0000| Dtrain_loss:0.1130|0.0393\n",
            "\n",
            " discrimnator prediction: 86.29%| 83.43%\n",
            "  4% 40/920 [06:39<2:26:52, 10.01s/it]\n",
            "Epoch:0    | Batch:40   | Gtrain_loss:0.0000| Dtrain_loss:0.0204|0.0082\n",
            "\n",
            " discrimnator prediction: 94.21%| 93.61%\n",
            "  7% 60/920 [09:55<2:20:19,  9.79s/it]\n",
            "Epoch:0    | Batch:60   | Gtrain_loss:0.0000| Dtrain_loss:0.0115|0.0048\n",
            "\n",
            " discrimnator prediction: 93.97%| 93.96%\n",
            "  9% 80/920 [13:12<2:12:41,  9.48s/it]\n",
            "Epoch:0    | Batch:80   | Gtrain_loss:0.0000| Dtrain_loss:0.0067|0.7078\n",
            "\n",
            " discrimnator prediction: 94.49%| 93.89%\n",
            " 10% 92/920 [15:11<2:17:07,  9.94s/it]\n",
            "============================Start Validation for fine tune Epoch: 0================================\n",
            "\n",
            "  1% 1/103 [15:21<26:06:25, 921.42s/it]\u001b[A\n",
            "  2% 2/103 [15:30<10:48:05, 385.01s/it]\u001b[A\n",
            "  3% 3/103 [15:39<5:55:28, 213.29s/it] \u001b[A\n",
            "  4% 4/103 [15:49<3:39:02, 132.75s/it]\u001b[A\n",
            "  5% 5/103 [15:58<2:24:00, 88.17s/it] \u001b[A\n",
            "  6% 6/103 [16:07<1:39:18, 61.43s/it]\u001b[A\n",
            "  7% 7/103 [16:16<1:10:56, 44.34s/it]\u001b[A\n",
            "  8% 8/103 [16:26<52:35, 33.22s/it]  \u001b[A\n",
            "  9% 9/103 [16:34<39:50, 25.43s/it]\u001b[A\n",
            " 10% 10/103 [16:43<31:34, 20.37s/it]\u001b[A\n",
            " 11% 11/103 [16:53<26:07, 17.04s/it]\u001b[A\n",
            " 12% 12/103 [17:00<21:22, 14.09s/it]\u001b[A\n",
            " 13% 13/103 [17:09<18:58, 12.65s/it]\u001b[A\n",
            " 14% 14/103 [17:18<17:09, 11.57s/it]\u001b[A\n",
            " 15% 15/103 [17:28<16:04, 10.95s/it]\u001b[A\n",
            " 16% 16/103 [17:37<15:12, 10.49s/it]\u001b[A\n",
            " 17% 17/103 [17:47<14:32, 10.15s/it]\u001b[A\n",
            " 17% 18/103 [17:56<13:56,  9.84s/it]\u001b[A\n",
            " 18% 19/103 [18:06<13:44,  9.82s/it]\u001b[A\n",
            " 19% 20/103 [18:15<13:16,  9.59s/it]\u001b[A\n",
            " 20% 21/103 [18:24<13:00,  9.52s/it]\u001b[A\n",
            " 21% 22/103 [18:33<12:46,  9.46s/it]\u001b[A\n",
            " 22% 23/103 [18:43<12:33,  9.41s/it]\u001b[A\n",
            " 23% 24/103 [18:52<12:23,  9.41s/it]\u001b[A\n",
            " 24% 25/103 [19:01<11:51,  9.12s/it]\u001b[A\n",
            " 25% 26/103 [19:10<11:49,  9.21s/it]\u001b[A\n",
            " 26% 27/103 [19:19<11:36,  9.17s/it]\u001b[A\n",
            " 27% 28/103 [19:29<11:36,  9.29s/it]\u001b[A\n",
            " 28% 29/103 [19:38<11:29,  9.31s/it]\u001b[A\n",
            " 29% 30/103 [19:47<11:21,  9.34s/it]\u001b[A\n",
            " 30% 31/103 [19:56<11:04,  9.23s/it]\u001b[A\n",
            " 31% 32/103 [20:06<10:58,  9.28s/it]\u001b[A\n",
            " 32% 33/103 [20:15<10:52,  9.32s/it]\u001b[A\n",
            " 33% 34/103 [20:24<10:38,  9.25s/it]\u001b[A\n",
            " 34% 35/103 [20:34<10:30,  9.27s/it]\u001b[A\n",
            " 35% 36/103 [20:43<10:22,  9.29s/it]\u001b[A\n",
            " 36% 37/103 [20:53<10:19,  9.38s/it]\u001b[A\n",
            " 37% 38/103 [21:02<10:05,  9.31s/it]\u001b[A\n",
            " 38% 39/103 [21:12<10:07,  9.49s/it]\u001b[A\n",
            " 39% 40/103 [21:21<09:48,  9.34s/it]\u001b[A\n",
            " 40% 41/103 [21:30<09:41,  9.38s/it]\u001b[A\n",
            " 41% 42/103 [21:39<09:31,  9.38s/it]\u001b[A\n",
            " 42% 43/103 [21:49<09:25,  9.42s/it]\u001b[A\n",
            " 43% 44/103 [21:57<08:45,  8.91s/it]\u001b[A\n",
            " 44% 45/103 [22:06<08:45,  9.05s/it]\u001b[A\n",
            " 45% 46/103 [22:15<08:35,  9.04s/it]\u001b[A\n",
            " 46% 47/103 [22:24<08:33,  9.17s/it]\u001b[A\n",
            " 47% 48/103 [22:34<08:28,  9.25s/it]\u001b[A\n",
            " 48% 49/103 [22:43<08:15,  9.18s/it]\u001b[A\n",
            " 49% 50/103 [22:52<08:10,  9.25s/it]\u001b[A\n",
            " 50% 51/103 [23:02<08:04,  9.31s/it]\u001b[A\n",
            " 50% 52/103 [23:11<07:53,  9.28s/it]\u001b[A\n",
            " 51% 53/103 [23:20<07:44,  9.30s/it]\u001b[A\n",
            " 52% 54/103 [23:28<07:10,  8.78s/it]\u001b[A\n",
            " 53% 55/103 [23:37<07:10,  8.98s/it]\u001b[A\n",
            " 54% 56/103 [23:47<07:07,  9.09s/it]\u001b[A\n",
            " 55% 57/103 [23:56<07:00,  9.15s/it]\u001b[A\n",
            " 56% 58/103 [24:05<06:53,  9.18s/it]\u001b[A\n",
            " 57% 59/103 [24:15<06:46,  9.24s/it]\u001b[A\n",
            " 58% 60/103 [24:24<06:33,  9.16s/it]\u001b[A\n",
            " 59% 61/103 [24:33<06:28,  9.24s/it]\u001b[A\n",
            " 60% 62/103 [24:42<06:16,  9.18s/it]\u001b[A\n",
            " 61% 63/103 [24:51<06:02,  9.06s/it]\u001b[A\n",
            " 62% 64/103 [25:00<05:51,  9.02s/it]\u001b[A\n",
            " 63% 65/103 [25:09<05:45,  9.09s/it]\u001b[A\n",
            " 64% 66/103 [25:19<05:40,  9.20s/it]\u001b[A\n",
            " 65% 67/103 [25:25<05:03,  8.42s/it]\u001b[A\n",
            " 66% 68/103 [25:34<05:04,  8.70s/it]\u001b[A\n",
            " 67% 69/103 [25:44<05:01,  8.87s/it]\u001b[A\n",
            " 68% 70/103 [25:53<04:58,  9.03s/it]\u001b[A\n",
            " 69% 71/103 [26:02<04:52,  9.13s/it]\u001b[A\n",
            " 70% 72/103 [26:12<04:43,  9.16s/it]\u001b[A\n",
            " 71% 73/103 [26:20<04:26,  8.90s/it]\u001b[A\n",
            " 72% 74/103 [26:29<04:21,  9.03s/it]\u001b[A\n",
            " 73% 75/103 [26:39<04:15,  9.12s/it]\u001b[A\n",
            " 74% 76/103 [26:48<04:06,  9.13s/it]\u001b[A\n",
            " 75% 77/103 [26:57<03:58,  9.18s/it]\u001b[A\n",
            " 76% 78/103 [27:06<03:50,  9.22s/it]\u001b[A\n",
            " 77% 79/103 [27:16<03:43,  9.30s/it]\u001b[A\n",
            " 78% 80/103 [27:20<02:57,  7.73s/it]\u001b[A\n",
            " 79% 81/103 [27:29<03:01,  8.24s/it]\u001b[A\n",
            " 80% 82/103 [27:39<02:58,  8.52s/it]\u001b[A\n",
            " 81% 83/103 [27:48<02:56,  8.83s/it]\u001b[A\n",
            " 82% 84/103 [27:58<02:51,  9.03s/it]\u001b[A\n",
            " 83% 85/103 [28:07<02:44,  9.13s/it]\u001b[A\n",
            " 83% 86/103 [28:16<02:35,  9.16s/it]\u001b[A\n",
            " 84% 87/103 [28:26<02:28,  9.26s/it]\u001b[A\n",
            " 85% 88/103 [28:35<02:19,  9.29s/it]\u001b[A\n",
            " 86% 89/103 [28:44<02:10,  9.31s/it]\u001b[A\n",
            " 87% 90/103 [28:53<01:57,  9.07s/it]\u001b[A\n",
            " 88% 91/103 [29:02<01:50,  9.20s/it]\u001b[A\n",
            " 89% 92/103 [29:12<01:41,  9.23s/it]\u001b[A\n",
            " 90% 93/103 [29:21<01:32,  9.29s/it]\u001b[A\n",
            " 91% 94/103 [29:31<01:24,  9.34s/it]\u001b[A\n",
            " 92% 95/103 [29:40<01:14,  9.27s/it]\u001b[A\n",
            " 93% 96/103 [29:49<01:04,  9.26s/it]\u001b[A\n",
            " 94% 97/103 [29:58<00:54,  9.11s/it]\u001b[A\n",
            " 95% 98/103 [30:07<00:45,  9.07s/it]\u001b[A\n",
            " 96% 99/103 [30:16<00:36,  9.18s/it]\u001b[A\n",
            " 97% 100/103 [30:26<00:27,  9.23s/it]\u001b[A\n",
            " 98% 101/103 [30:35<00:18,  9.28s/it]\u001b[A\n",
            " 99% 102/103 [30:44<00:09,  9.32s/it]\u001b[A\n",
            "100% 103/103 [30:48<00:00,  7.60s/it]\u001b[A\n",
            "Epoch:0    | validation_loss:16.8619\n",
            "\n",
            "rouge1:0.2533| rouge2:0.0893| rougeL:0.1924| rougeLsum:0.1921\n",
            "\n",
            "=============================End Validation for fine tune Epoch: 0==================================\n",
            "\n",
            "==============================saving model for fine tune: 1==================================\n",
            "\n",
            "\n",
            "100% 103/103 [30:54<00:00, 18.01s/it]\n",
            "\n",
            "Epoch:1    | Batch:0    | Gtrain_loss:16.2552| Dtrain_loss:0.0048|0.0027\n",
            "\n",
            " discrimnator prediction: 94.72%| 94.72%\n",
            " 12% 112/920 [34:37<2:33:20, 11.39s/it]\n",
            "Epoch:1    | Batch:20   | Gtrain_loss:7.3091| Dtrain_loss:0.0051|0.0043\n",
            "\n",
            " discrimnator prediction: 94.04%| 93.43%\n",
            " 14% 132/920 [38:20<2:26:59, 11.19s/it]\n",
            "Epoch:1    | Batch:40   | Gtrain_loss:3.8934| Dtrain_loss:0.0058|0.0025\n",
            "\n",
            " discrimnator prediction: 94.21%| 94.21%\n",
            " 17% 152/920 [41:42<1:41:02,  7.89s/it]\n",
            "Epoch:1    | Batch:60   | Gtrain_loss:2.3614| Dtrain_loss:0.3606|0.4754\n",
            "\n",
            " discrimnator prediction: 91.13%| 83.82%\n",
            " 19% 172/920 [43:07<42:46,  3.43s/it]\n",
            "Epoch:1    | Batch:80   | Gtrain_loss:1.2333| Dtrain_loss:0.4818|0.7103\n",
            "\n",
            " discrimnator prediction: 79.88%| 53.74%\n",
            " 20% 184/920 [44:01<48:00,  3.91s/it]\n",
            "============================Start Validation for fine tune Epoch: 1================================\n",
            "\n",
            "\n",
            "  1% 1/103 [13:08<22:20:08, 788.32s/it]\u001b[A\u001b[A\n",
            "\n",
            "  2% 2/103 [13:09<9:07:44, 325.39s/it] \u001b[A\u001b[A\n",
            "\n",
            "  3% 3/103 [13:10<4:55:40, 177.41s/it]\u001b[A\u001b[A\n",
            "\n",
            "  4% 4/103 [13:12<2:58:09, 107.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "  5% 5/103 [13:13<1:53:38, 69.57s/it] \u001b[A\u001b[A\n",
            "\n",
            "  6% 6/103 [13:15<1:14:57, 46.37s/it]\u001b[A\u001b[A\n",
            "\n",
            "  7% 7/103 [13:17<50:51, 31.79s/it]  \u001b[A\u001b[A\n",
            "\n",
            "  8% 8/103 [13:19<35:25, 22.38s/it]\u001b[A\u001b[A\n",
            "\n",
            "  9% 9/103 [13:20<24:47, 15.82s/it]\u001b[A\u001b[A\n",
            "\n",
            " 10% 10/103 [13:22<17:47, 11.47s/it]\u001b[A\u001b[A\n",
            "\n",
            " 11% 11/103 [13:23<12:50,  8.38s/it]\u001b[A\u001b[A\n",
            "\n",
            " 12% 12/103 [13:25<09:24,  6.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 13% 13/103 [13:26<07:06,  4.74s/it]\u001b[A\u001b[A\n",
            "\n",
            " 14% 14/103 [13:27<05:25,  3.66s/it]\u001b[A\u001b[A\n",
            "\n",
            " 15% 15/103 [13:29<04:26,  3.03s/it]\u001b[A\u001b[A\n",
            "\n",
            " 16% 16/103 [13:30<03:41,  2.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17% 17/103 [13:32<03:12,  2.24s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17% 18/103 [13:33<02:47,  1.97s/it]\u001b[A\u001b[A\n",
            "\n",
            " 18% 19/103 [13:34<02:26,  1.74s/it]\u001b[A\u001b[A\n",
            "\n",
            " 19% 20/103 [13:36<02:16,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 20% 21/103 [13:37<02:05,  1.53s/it]\u001b[A\u001b[A\n",
            "\n",
            " 21% 22/103 [13:39<02:08,  1.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 22% 23/103 [13:40<02:07,  1.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 23% 24/103 [13:41<01:59,  1.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 24% 25/103 [13:43<01:54,  1.47s/it]\u001b[A\u001b[A\n",
            "\n",
            " 25% 26/103 [13:44<01:50,  1.43s/it]\u001b[A\u001b[A\n",
            "\n",
            " 26% 27/103 [13:46<01:54,  1.50s/it]\u001b[A\u001b[A\n",
            "\n",
            " 27% 28/103 [13:47<01:53,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 28% 29/103 [13:49<02:00,  1.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 29% 30/103 [13:51<01:59,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 30% 31/103 [13:52<01:53,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 31% 32/103 [13:54<01:49,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 32% 33/103 [13:55<01:47,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33% 34/103 [13:58<02:00,  1.75s/it]\u001b[A\u001b[A\n",
            "\n",
            " 34% 35/103 [14:00<02:02,  1.80s/it]\u001b[A\u001b[A\n",
            "\n",
            " 35% 36/103 [14:01<01:53,  1.69s/it]\u001b[A\u001b[A\n",
            "\n",
            " 36% 37/103 [14:03<01:49,  1.65s/it]\u001b[A\u001b[A\n",
            "\n",
            " 37% 38/103 [14:04<01:46,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 38% 39/103 [14:07<01:59,  1.87s/it]\u001b[A\u001b[A\n",
            "\n",
            " 39% 40/103 [14:08<01:50,  1.75s/it]\u001b[A\u001b[A\n",
            "\n",
            " 40% 41/103 [14:10<01:45,  1.70s/it]\u001b[A\u001b[A\n",
            "\n",
            " 41% 42/103 [14:11<01:36,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 42% 43/103 [14:13<01:49,  1.83s/it]\u001b[A\u001b[A\n",
            "\n",
            " 43% 44/103 [14:15<01:39,  1.69s/it]\u001b[A\u001b[A\n",
            "\n",
            " 44% 45/103 [14:16<01:37,  1.67s/it]\u001b[A\u001b[A\n",
            "\n",
            " 45% 46/103 [14:18<01:28,  1.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 46% 47/103 [14:19<01:31,  1.63s/it]\u001b[A\u001b[A\n",
            "\n",
            " 47% 48/103 [14:21<01:26,  1.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 48% 49/103 [14:22<01:24,  1.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 49% 50/103 [14:24<01:24,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50% 51/103 [14:26<01:21,  1.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50% 52/103 [14:27<01:14,  1.46s/it]\u001b[A\u001b[A\n",
            "\n",
            " 51% 53/103 [14:28<01:10,  1.42s/it]\u001b[A\u001b[A\n",
            "\n",
            " 52% 54/103 [14:29<01:06,  1.36s/it]\u001b[A\u001b[A\n",
            "\n",
            " 53% 55/103 [14:31<01:06,  1.39s/it]\u001b[A\u001b[A\n",
            "\n",
            " 54% 56/103 [14:32<01:03,  1.36s/it]\u001b[A\u001b[A\n",
            "\n",
            " 55% 57/103 [14:34<01:06,  1.44s/it]\u001b[A\u001b[A\n",
            "\n",
            " 56% 58/103 [14:35<01:04,  1.42s/it]\u001b[A\u001b[A\n",
            "\n",
            " 57% 59/103 [14:37<01:04,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 58% 60/103 [14:39<01:09,  1.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 59% 61/103 [14:40<01:04,  1.53s/it]\u001b[A\u001b[A\n",
            "\n",
            " 60% 62/103 [14:41<01:00,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 61% 63/103 [14:43<00:57,  1.44s/it]\u001b[A\u001b[A\n",
            "\n",
            " 62% 64/103 [14:44<00:56,  1.45s/it]\u001b[A\u001b[A\n",
            "\n",
            " 63% 65/103 [14:45<00:53,  1.40s/it]\u001b[A\u001b[A\n",
            "\n",
            " 64% 66/103 [14:47<00:51,  1.40s/it]\u001b[A\u001b[A\n",
            "\n",
            " 65% 67/103 [14:48<00:52,  1.47s/it]\u001b[A\u001b[A\n",
            "\n",
            " 66% 68/103 [14:51<01:00,  1.73s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67% 69/103 [14:52<00:55,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 68% 70/103 [14:54<00:52,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 69% 71/103 [14:55<00:51,  1.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 70% 72/103 [14:57<00:47,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 71% 73/103 [14:58<00:44,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 72% 74/103 [14:59<00:41,  1.43s/it]\u001b[A\u001b[A\n",
            "\n",
            " 73% 75/103 [15:01<00:39,  1.41s/it]\u001b[A\u001b[A\n",
            "\n",
            " 74% 76/103 [15:02<00:36,  1.36s/it]\u001b[A\u001b[A\n",
            "\n",
            " 75% 77/103 [15:04<00:38,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 76% 78/103 [15:06<00:39,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 77% 79/103 [15:07<00:40,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 78% 80/103 [15:09<00:36,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 79% 81/103 [15:10<00:33,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 80% 82/103 [15:12<00:33,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 81% 83/103 [15:13<00:31,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 82% 84/103 [15:15<00:29,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83% 85/103 [15:17<00:28,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83% 86/103 [15:19<00:29,  1.74s/it]\u001b[A\u001b[A\n",
            "\n",
            " 84% 87/103 [15:20<00:26,  1.66s/it]\u001b[A\u001b[A\n",
            "\n",
            " 85% 88/103 [15:22<00:25,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 86% 89/103 [15:24<00:24,  1.74s/it]\u001b[A\u001b[A\n",
            "\n",
            " 87% 90/103 [15:25<00:22,  1.70s/it]\u001b[A\u001b[A\n",
            "\n",
            " 88% 91/103 [15:35<00:48,  4.02s/it]\u001b[A\u001b[A\n",
            "\n",
            " 89% 92/103 [15:44<01:00,  5.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 90% 93/103 [15:46<00:43,  4.36s/it]\u001b[A\u001b[A\n",
            "\n",
            " 91% 94/103 [15:47<00:31,  3.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 92% 95/103 [15:49<00:24,  3.11s/it]\u001b[A\u001b[A\n",
            "\n",
            " 93% 96/103 [15:51<00:18,  2.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 94% 97/103 [15:52<00:13,  2.32s/it]\u001b[A\u001b[A\n",
            "\n",
            " 95% 98/103 [15:54<00:10,  2.06s/it]\u001b[A\u001b[A\n",
            "\n",
            " 96% 99/103 [15:55<00:07,  1.88s/it]\u001b[A\u001b[A\n",
            "\n",
            " 97% 100/103 [15:57<00:05,  1.90s/it]\u001b[A\u001b[A\n",
            "\n",
            " 98% 101/103 [15:59<00:03,  1.84s/it]\u001b[A\u001b[A\n",
            "\n",
            " 99% 102/103 [16:01<00:01,  1.89s/it]\u001b[A\u001b[A\n",
            "\n",
            "100% 103/103 [16:02<00:00,  1.52s/it]\u001b[A\u001b[A\n",
            "Epoch:1    | validation_loss:0.5288\n",
            "\n",
            "rouge1:0.3819| rouge2:0.1586| rougeL:0.3148| rougeLsum:0.3147\n",
            "\n",
            "=============================End Validation for fine tune Epoch: 1==================================\n",
            "\n",
            "==============================saving model for fine tune: 2==================================\n",
            "\n",
            "100% 103/103 [16:10<00:00,  9.42s/it]\n",
            "\n",
            "Epoch:2    | Batch:0    | Gtrain_loss:0.7791| Dtrain_loss:0.2865|1.0399\n",
            "\n",
            " discrimnator prediction: 61.94%| 59.43%\n",
            " 22% 204/920 [48:22<44:19,  3.71s/it]\n",
            "Epoch:2    | Batch:20   | Gtrain_loss:0.4751| Dtrain_loss:0.6521|0.3551\n",
            "\n",
            " discrimnator prediction: 71.28%| 69.30%\n",
            " 24% 224/920 [49:35<42:53,  3.70s/it]\n",
            "Epoch:2    | Batch:40   | Gtrain_loss:0.3009| Dtrain_loss:1.1003|0.1098\n",
            "\n",
            " discrimnator prediction: 70.17%| 73.73%\n",
            " 27% 244/920 [50:45<39:02,  3.47s/it]\n",
            "Epoch:2    | Batch:60   | Gtrain_loss:0.2536| Dtrain_loss:0.3393|0.6221\n",
            "\n",
            " discrimnator prediction: 62.75%| 79.37%\n",
            " 29% 264/920 [51:52<36:08,  3.31s/it]\n",
            "Epoch:2    | Batch:80   | Gtrain_loss:0.2387| Dtrain_loss:0.1388|0.8316\n",
            "\n",
            " discrimnator prediction: 77.59%| 73.40%\n",
            " 30% 276/920 [52:35<38:17,  3.57s/it]\n",
            "============================Start Validation for fine tune Epoch: 2================================\n",
            "\n",
            "  1% 1/103 [05:31<9:24:05, 331.82s/it]\u001b[A\n",
            "  2% 2/103 [05:33<3:51:39, 137.62s/it]\u001b[A\n",
            "  3% 3/103 [05:34<2:05:39, 75.40s/it] \u001b[A\n",
            "  4% 4/103 [05:36<1:16:12, 46.18s/it]\u001b[A\n",
            "  5% 5/103 [05:37<49:00, 30.01s/it]  \u001b[A\n",
            "  6% 6/103 [05:38<32:45, 20.27s/it]\u001b[A\n",
            "  7% 7/103 [05:40<22:34, 14.11s/it]\u001b[A\n",
            "  8% 8/103 [05:42<16:24, 10.37s/it]\u001b[A\n",
            "  9% 9/103 [05:44<11:50,  7.56s/it]\u001b[A\n",
            " 10% 10/103 [05:46<09:08,  5.90s/it]\u001b[A\n",
            " 11% 11/103 [05:47<06:52,  4.48s/it]\u001b[A\n",
            " 12% 12/103 [05:48<05:15,  3.47s/it]\u001b[A\n",
            " 13% 13/103 [05:50<04:13,  2.82s/it]\u001b[A\n",
            " 14% 14/103 [05:51<03:36,  2.43s/it]\u001b[A\n",
            " 15% 15/103 [05:53<03:14,  2.21s/it]\u001b[A\n",
            " 16% 16/103 [05:54<02:49,  1.94s/it]\u001b[A\n",
            " 17% 17/103 [05:56<02:34,  1.79s/it]\u001b[A\n",
            " 17% 18/103 [05:57<02:30,  1.77s/it]\u001b[A\n",
            " 18% 19/103 [05:58<02:15,  1.61s/it]\u001b[A\n",
            " 19% 20/103 [06:00<02:13,  1.61s/it]\u001b[A\n",
            " 20% 21/103 [06:02<02:08,  1.57s/it]\u001b[A\n",
            " 21% 22/103 [06:03<02:13,  1.65s/it]\u001b[A\n",
            " 22% 23/103 [06:05<02:11,  1.65s/it]\u001b[A\n",
            " 23% 24/103 [06:07<02:07,  1.61s/it]\u001b[A\n",
            " 24% 25/103 [06:08<01:56,  1.50s/it]\u001b[A\n",
            " 25% 26/103 [06:09<01:56,  1.52s/it]\u001b[A\n",
            " 26% 27/103 [06:11<01:55,  1.53s/it]\u001b[A\n",
            " 27% 28/103 [06:13<02:05,  1.68s/it]\u001b[A\n",
            " 28% 29/103 [06:14<02:01,  1.64s/it]\u001b[A\n",
            " 29% 30/103 [06:16<01:55,  1.59s/it]\u001b[A\n",
            " 30% 31/103 [06:17<01:52,  1.57s/it]\u001b[A\n",
            " 31% 32/103 [06:19<01:44,  1.47s/it]\u001b[A\n",
            " 32% 33/103 [06:20<01:40,  1.44s/it]\u001b[A\n",
            " 33% 34/103 [06:22<01:47,  1.56s/it]\u001b[A\n",
            " 34% 35/103 [06:24<01:46,  1.57s/it]\u001b[A\n",
            " 35% 36/103 [06:25<01:44,  1.56s/it]\u001b[A\n",
            " 36% 37/103 [06:27<01:45,  1.59s/it]\u001b[A\n",
            " 37% 38/103 [06:28<01:36,  1.48s/it]\u001b[A\n",
            " 38% 39/103 [06:30<01:45,  1.65s/it]\u001b[A\n",
            " 39% 40/103 [06:32<01:43,  1.65s/it]\u001b[A\n",
            " 40% 41/103 [06:33<01:41,  1.64s/it]\u001b[A\n",
            " 41% 42/103 [06:35<01:34,  1.54s/it]\u001b[A\n",
            " 42% 43/103 [06:36<01:33,  1.56s/it]\u001b[A\n",
            " 43% 44/103 [06:38<01:28,  1.50s/it]\u001b[A\n",
            " 44% 45/103 [06:39<01:33,  1.61s/it]\u001b[A\n",
            " 45% 46/103 [06:41<01:26,  1.51s/it]\u001b[A\n",
            " 46% 47/103 [06:42<01:26,  1.55s/it]\u001b[A\n",
            " 47% 48/103 [06:44<01:23,  1.51s/it]\u001b[A\n",
            " 48% 49/103 [06:45<01:22,  1.52s/it]\u001b[A\n",
            " 49% 50/103 [06:47<01:19,  1.49s/it]\u001b[A\n",
            " 50% 51/103 [06:48<01:19,  1.52s/it]\u001b[A\n",
            " 50% 52/103 [06:49<01:12,  1.42s/it]\u001b[A\n",
            " 51% 53/103 [06:51<01:10,  1.42s/it]\u001b[A\n",
            " 52% 54/103 [06:52<01:05,  1.34s/it]\u001b[A\n",
            " 53% 55/103 [06:53<01:05,  1.36s/it]\u001b[A\n",
            " 54% 56/103 [06:55<01:01,  1.32s/it]\u001b[A\n",
            " 55% 57/103 [06:56<01:05,  1.42s/it]\u001b[A\n",
            " 56% 58/103 [06:58<01:02,  1.39s/it]\u001b[A\n",
            " 57% 59/103 [06:59<01:03,  1.44s/it]\u001b[A\n",
            " 58% 60/103 [07:01<01:01,  1.43s/it]\u001b[A\n",
            " 59% 61/103 [07:02<00:56,  1.35s/it]\u001b[A\n",
            " 60% 62/103 [07:03<00:53,  1.32s/it]\u001b[A\n",
            " 61% 63/103 [07:04<00:53,  1.33s/it]\u001b[A\n",
            " 62% 64/103 [07:06<00:52,  1.35s/it]\u001b[A\n",
            " 63% 65/103 [07:07<00:51,  1.36s/it]\u001b[A\n",
            " 64% 66/103 [07:08<00:49,  1.35s/it]\u001b[A\n",
            " 65% 67/103 [07:10<00:48,  1.34s/it]\u001b[A\n",
            " 66% 68/103 [07:11<00:50,  1.44s/it]\u001b[A\n",
            " 67% 69/103 [07:13<00:48,  1.42s/it]\u001b[A\n",
            " 68% 70/103 [07:14<00:46,  1.41s/it]\u001b[A\n",
            " 69% 71/103 [07:16<00:45,  1.43s/it]\u001b[A\n",
            " 70% 72/103 [07:17<00:44,  1.43s/it]\u001b[A\n",
            " 71% 73/103 [07:18<00:41,  1.37s/it]\u001b[A\n",
            " 72% 74/103 [07:20<00:39,  1.35s/it]\u001b[A\n",
            " 73% 75/103 [07:21<00:37,  1.32s/it]\u001b[A\n",
            " 74% 76/103 [07:22<00:34,  1.26s/it]\u001b[A\n",
            " 75% 77/103 [07:24<00:34,  1.33s/it]\u001b[A\n",
            " 76% 78/103 [07:26<00:38,  1.54s/it]\u001b[A\n",
            " 77% 79/103 [07:27<00:38,  1.62s/it]\u001b[A\n",
            " 78% 80/103 [07:29<00:34,  1.52s/it]\u001b[A\n",
            " 79% 81/103 [07:30<00:33,  1.52s/it]\u001b[A\n",
            " 80% 82/103 [07:32<00:32,  1.54s/it]\u001b[A\n",
            " 81% 83/103 [07:33<00:31,  1.56s/it]\u001b[A\n",
            " 82% 84/103 [07:35<00:28,  1.52s/it]\u001b[A\n",
            " 83% 85/103 [07:36<00:27,  1.52s/it]\u001b[A\n",
            " 83% 86/103 [07:38<00:27,  1.59s/it]\u001b[A\n",
            " 84% 87/103 [07:40<00:26,  1.69s/it]\u001b[A\n",
            " 85% 88/103 [07:42<00:24,  1.64s/it]\u001b[A\n",
            " 86% 89/103 [07:43<00:23,  1.65s/it]\u001b[A\n",
            " 87% 90/103 [07:45<00:20,  1.58s/it]\u001b[A\n",
            " 88% 91/103 [07:46<00:18,  1.53s/it]\u001b[A\n",
            " 89% 92/103 [07:47<00:16,  1.46s/it]\u001b[A\n",
            " 90% 93/103 [07:49<00:15,  1.52s/it]\u001b[A\n",
            " 91% 94/103 [07:50<00:13,  1.46s/it]\u001b[A\n",
            " 92% 95/103 [07:53<00:13,  1.70s/it]\u001b[A\n",
            " 93% 96/103 [07:54<00:12,  1.73s/it]\u001b[A\n",
            " 94% 97/103 [07:56<00:09,  1.64s/it]\u001b[A\n",
            " 95% 98/103 [07:57<00:07,  1.52s/it]\u001b[A\n",
            " 96% 99/103 [07:58<00:05,  1.41s/it]\u001b[A\n",
            " 97% 100/103 [08:00<00:04,  1.51s/it]\u001b[A\n",
            " 98% 101/103 [08:02<00:03,  1.54s/it]\u001b[A\n",
            " 99% 102/103 [08:03<00:01,  1.58s/it]\u001b[A\n",
            "100% 103/103 [08:04<00:00,  1.30s/it]\u001b[A\n",
            "Epoch:2    | validation_loss:0.1445\n",
            "\n",
            "rouge1:0.4017| rouge2:0.1794| rougeL:0.3334| rougeLsum:0.3335\n",
            "\n",
            "=============================End Validation for fine tune Epoch: 2==================================\n",
            "\n",
            "==============================saving model for fine tune: 3==================================\n",
            "\n",
            "\n",
            "100% 103/103 [08:16<00:00,  4.82s/it]\n",
            "\n",
            "Epoch:3    | Batch:0    | Gtrain_loss:0.2049| Dtrain_loss:0.4833|0.5904\n",
            "\n",
            " discrimnator prediction: 63.60%| 70.24%\n",
            " 32% 296/920 [56:30<37:35,  3.61s/it]\n",
            "Epoch:3    | Batch:20   | Gtrain_loss:0.2140| Dtrain_loss:0.2681|0.0954\n",
            "\n",
            " discrimnator prediction: 74.11%| 80.01%\n",
            " 34% 316/920 [57:41<37:54,  3.77s/it]\n",
            "Epoch:3    | Batch:40   | Gtrain_loss:0.1561| Dtrain_loss:0.6409|0.1829\n",
            "\n",
            " discrimnator prediction: 72.55%| 83.15%\n",
            " 37% 336/920 [58:47<31:23,  3.23s/it]\n",
            "Epoch:3    | Batch:60   | Gtrain_loss:0.1650| Dtrain_loss:0.4272|0.8271\n",
            "\n",
            " discrimnator prediction: 70.46%| 80.40%\n",
            " 39% 356/920 [59:53<33:34,  3.57s/it]\n",
            "Epoch:3    | Batch:80   | Gtrain_loss:0.1777| Dtrain_loss:0.1229|0.3937\n",
            "\n",
            " discrimnator prediction: 82.50%| 74.33%\n",
            " 40% 368/920 [1:00:35<32:49,  3.57s/it]\n",
            "============================Start Validation for fine tune Epoch: 3================================\n",
            "\n",
            "\n",
            "  1% 1/103 [05:15<8:56:10, 315.40s/it]\u001b[A\u001b[A\n",
            "\n",
            "  2% 2/103 [05:16<3:40:07, 130.77s/it]\u001b[A\u001b[A\n",
            "\n",
            "  3% 3/103 [05:18<1:59:30, 71.71s/it] \u001b[A\u001b[A\n",
            "\n",
            "  4% 4/103 [05:19<1:12:38, 44.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "  5% 5/103 [05:21<46:44, 28.62s/it]  \u001b[A\u001b[A\n",
            "\n",
            "  6% 6/103 [05:22<31:16, 19.34s/it]\u001b[A\u001b[A\n",
            "\n",
            "  7% 7/103 [05:24<21:34, 13.49s/it]\u001b[A\u001b[A\n",
            "\n",
            "  8% 8/103 [05:26<15:37,  9.87s/it]\u001b[A\u001b[A\n",
            "\n",
            "  9% 9/103 [05:27<11:18,  7.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 10% 10/103 [05:29<08:42,  5.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 11% 11/103 [05:30<06:35,  4.30s/it]\u001b[A\u001b[A\n",
            "\n",
            " 12% 12/103 [05:32<05:04,  3.35s/it]\u001b[A\u001b[A\n",
            "\n",
            " 13% 13/103 [05:33<04:09,  2.77s/it]\u001b[A\u001b[A\n",
            "\n",
            " 14% 14/103 [05:35<03:39,  2.47s/it]\u001b[A\u001b[A\n",
            "\n",
            " 15% 15/103 [05:36<03:12,  2.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 16% 16/103 [05:38<02:53,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17% 17/103 [05:39<02:31,  1.76s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17% 18/103 [05:41<02:22,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 18% 19/103 [05:42<02:11,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 19% 20/103 [05:44<02:12,  1.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 20% 21/103 [05:45<02:06,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 21% 22/103 [05:47<02:07,  1.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 22% 23/103 [05:48<02:06,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 23% 24/103 [05:50<02:07,  1.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 24% 25/103 [05:51<02:00,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 25% 26/103 [05:53<02:05,  1.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 26% 27/103 [05:55<02:08,  1.69s/it]\u001b[A\u001b[A\n",
            "\n",
            " 27% 28/103 [05:57<02:07,  1.69s/it]\u001b[A\u001b[A\n",
            "\n",
            " 28% 29/103 [05:58<02:01,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 29% 30/103 [06:00<01:55,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 30% 31/103 [06:01<01:52,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 31% 32/103 [06:02<01:45,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 32% 33/103 [06:04<01:46,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33% 34/103 [06:06<01:58,  1.72s/it]\u001b[A\u001b[A\n",
            "\n",
            " 34% 35/103 [06:08<01:54,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 35% 36/103 [06:09<01:48,  1.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 36% 37/103 [06:11<01:49,  1.66s/it]\u001b[A\u001b[A\n",
            "\n",
            " 37% 38/103 [06:12<01:40,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 38% 39/103 [06:14<01:42,  1.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 39% 40/103 [06:16<01:42,  1.63s/it]\u001b[A\u001b[A\n",
            "\n",
            " 40% 41/103 [06:17<01:37,  1.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 41% 42/103 [06:19<01:32,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 42% 43/103 [06:20<01:32,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 43% 44/103 [06:22<01:28,  1.49s/it]\u001b[A\u001b[A\n",
            "\n",
            " 44% 45/103 [06:23<01:34,  1.63s/it]\u001b[A\u001b[A\n",
            "\n",
            " 45% 46/103 [06:25<01:26,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 46% 47/103 [06:26<01:23,  1.49s/it]\u001b[A\u001b[A\n",
            "\n",
            " 47% 48/103 [06:28<01:24,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 48% 49/103 [06:29<01:24,  1.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 49% 50/103 [06:31<01:22,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50% 51/103 [06:33<01:25,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50% 52/103 [06:34<01:21,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 51% 53/103 [06:36<01:17,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 52% 54/103 [06:37<01:16,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 53% 55/103 [06:39<01:12,  1.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 54% 56/103 [06:40<01:13,  1.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 55% 57/103 [06:42<01:14,  1.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 56% 58/103 [06:43<01:07,  1.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 57% 59/103 [06:45<01:07,  1.53s/it]\u001b[A\u001b[A\n",
            "\n",
            " 58% 60/103 [06:46<01:03,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 59% 61/103 [06:48<00:59,  1.41s/it]\u001b[A\u001b[A\n",
            "\n",
            " 60% 62/103 [06:49<00:55,  1.36s/it]\u001b[A\u001b[A\n",
            "\n",
            " 61% 63/103 [06:50<00:54,  1.35s/it]\u001b[A\u001b[A\n",
            "\n",
            " 62% 64/103 [06:52<00:53,  1.36s/it]\u001b[A\u001b[A\n",
            "\n",
            " 63% 65/103 [06:53<00:56,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 64% 66/103 [06:55<00:53,  1.44s/it]\u001b[A\u001b[A\n",
            "\n",
            " 65% 67/103 [06:56<00:50,  1.40s/it]\u001b[A\u001b[A\n",
            "\n",
            " 66% 68/103 [06:57<00:49,  1.42s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67% 69/103 [06:59<00:46,  1.37s/it]\u001b[A\u001b[A\n",
            "\n",
            " 68% 70/103 [07:00<00:45,  1.39s/it]\u001b[A\u001b[A\n",
            "\n",
            " 69% 71/103 [07:02<00:47,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 70% 72/103 [07:03<00:46,  1.50s/it]\u001b[A\u001b[A\n",
            "\n",
            " 71% 73/103 [07:05<00:43,  1.45s/it]\u001b[A\u001b[A\n",
            "\n",
            " 72% 74/103 [07:06<00:42,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 73% 75/103 [07:08<00:41,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 74% 76/103 [07:09<00:37,  1.39s/it]\u001b[A\u001b[A\n",
            "\n",
            " 75% 77/103 [07:10<00:36,  1.39s/it]\u001b[A\u001b[A\n",
            "\n",
            " 76% 78/103 [07:13<00:41,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 77% 79/103 [07:14<00:39,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 78% 80/103 [07:15<00:34,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 79% 81/103 [07:17<00:34,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 80% 82/103 [07:19<00:33,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 81% 83/103 [07:20<00:32,  1.63s/it]\u001b[A\u001b[A\n",
            "\n",
            " 82% 84/103 [07:22<00:31,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83% 85/103 [07:24<00:28,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83% 86/103 [07:25<00:27,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 84% 87/103 [07:27<00:27,  1.70s/it]\u001b[A\u001b[A\n",
            "\n",
            " 85% 88/103 [07:29<00:24,  1.65s/it]\u001b[A\u001b[A\n",
            "\n",
            " 86% 89/103 [07:30<00:22,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 87% 90/103 [07:32<00:20,  1.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 88% 91/103 [07:33<00:18,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 89% 92/103 [07:35<00:17,  1.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 90% 93/103 [07:37<00:15,  1.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 91% 94/103 [07:38<00:13,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 92% 95/103 [07:40<00:13,  1.65s/it]\u001b[A\u001b[A\n",
            "\n",
            " 93% 96/103 [07:42<00:11,  1.69s/it]\u001b[A\u001b[A\n",
            "\n",
            " 94% 97/103 [07:43<00:09,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 95% 98/103 [07:44<00:07,  1.49s/it]\u001b[A\u001b[A\n",
            "\n",
            " 96% 99/103 [07:45<00:05,  1.37s/it]\u001b[A\u001b[A\n",
            "\n",
            " 97% 100/103 [07:47<00:04,  1.50s/it]\u001b[A\u001b[A\n",
            "\n",
            " 98% 101/103 [07:49<00:03,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 99% 102/103 [07:50<00:01,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            "100% 103/103 [07:51<00:00,  1.27s/it]\u001b[A\u001b[A\n",
            "Epoch:3    | validation_loss:0.1181\n",
            "\n",
            "rouge1:0.4144| rouge2:0.1895| rougeL:0.3460| rougeLsum:0.3462\n",
            "\n",
            "=============================End Validation for fine tune Epoch: 3==================================\n",
            "\n",
            "==============================saving model for fine tune: 4==================================\n",
            "\n",
            "100% 103/103 [08:02<00:00,  4.69s/it]\n",
            "\n",
            "Epoch:4    | Batch:0    | Gtrain_loss:0.1470| Dtrain_loss:0.4188|0.7566\n",
            "\n",
            " discrimnator prediction: 71.60%| 67.35%\n",
            " 42% 388/920 [1:04:32<30:53,  3.48s/it]\n",
            "Epoch:4    | Batch:20   | Gtrain_loss:0.1692| Dtrain_loss:0.1774|0.1850\n",
            "\n",
            " discrimnator prediction: 80.16%| 76.42%\n",
            " 44% 408/920 [1:05:41<28:54,  3.39s/it]\n",
            "Epoch:4    | Batch:40   | Gtrain_loss:0.1280| Dtrain_loss:0.5872|0.1862\n",
            "\n",
            " discrimnator prediction: 74.95%| 81.37%\n",
            " 47% 428/920 [1:06:48<26:55,  3.28s/it]\n",
            "Epoch:4    | Batch:60   | Gtrain_loss:0.1395| Dtrain_loss:0.4328|0.2396\n",
            "\n",
            " discrimnator prediction: 75.19%| 85.70%\n",
            " 49% 448/920 [1:07:54<26:26,  3.36s/it]\n",
            "Epoch:4    | Batch:80   | Gtrain_loss:0.1619| Dtrain_loss:0.0942|0.2468\n",
            "\n",
            " discrimnator prediction: 84.26%| 82.64%\n",
            " 50% 460/920 [1:08:36<26:37,  3.47s/it]\n",
            "============================Start Validation for fine tune Epoch: 4================================\n",
            "\n",
            "  1% 1/103 [05:13<8:52:30, 313.24s/it]\u001b[A\n",
            "  2% 2/103 [05:14<3:38:37, 129.88s/it]\u001b[A\n",
            "  3% 3/103 [05:16<1:58:35, 71.16s/it] \u001b[A\n",
            "  4% 4/103 [05:17<1:12:01, 43.65s/it]\u001b[A\n",
            "  5% 5/103 [05:18<46:23, 28.40s/it]  \u001b[A\n",
            "  6% 6/103 [05:20<31:04, 19.22s/it]\u001b[A\n",
            "  7% 7/103 [05:21<21:27, 13.41s/it]\u001b[A\n",
            "  8% 8/103 [05:23<15:20,  9.69s/it]\u001b[A\n",
            "  9% 9/103 [05:24<11:07,  7.11s/it]\u001b[A\n",
            " 10% 10/103 [05:26<08:22,  5.41s/it]\u001b[A\n",
            " 11% 11/103 [05:27<06:23,  4.17s/it]\u001b[A\n",
            " 12% 12/103 [05:28<04:55,  3.25s/it]\u001b[A\n",
            " 13% 13/103 [05:30<04:01,  2.68s/it]\u001b[A\n",
            " 14% 14/103 [05:31<03:30,  2.36s/it]\u001b[A\n",
            " 15% 15/103 [05:33<03:10,  2.16s/it]\u001b[A\n",
            " 16% 16/103 [05:34<02:45,  1.90s/it]\u001b[A\n",
            " 17% 17/103 [05:36<02:31,  1.76s/it]\u001b[A\n",
            " 17% 18/103 [05:37<02:23,  1.68s/it]\u001b[A\n",
            " 18% 19/103 [05:39<02:14,  1.60s/it]\u001b[A\n",
            " 19% 20/103 [05:40<02:14,  1.61s/it]\u001b[A\n",
            " 20% 21/103 [05:42<02:07,  1.56s/it]\u001b[A\n",
            " 21% 22/103 [05:44<02:11,  1.63s/it]\u001b[A\n",
            " 22% 23/103 [05:45<02:04,  1.55s/it]\u001b[A\n",
            " 23% 24/103 [05:47<02:03,  1.57s/it]\u001b[A\n",
            " 24% 25/103 [05:48<01:55,  1.48s/it]\u001b[A\n",
            " 25% 26/103 [05:50<01:56,  1.51s/it]\u001b[A\n",
            " 26% 27/103 [05:51<01:54,  1.51s/it]\u001b[A\n",
            " 27% 28/103 [05:53<02:01,  1.62s/it]\u001b[A\n",
            " 28% 29/103 [05:55<02:01,  1.64s/it]\u001b[A\n",
            " 29% 30/103 [05:56<01:53,  1.56s/it]\u001b[A\n",
            " 30% 31/103 [05:58<01:51,  1.55s/it]\u001b[A\n",
            " 31% 32/103 [05:59<01:47,  1.52s/it]\u001b[A\n",
            " 32% 33/103 [06:01<01:49,  1.56s/it]\u001b[A\n",
            " 33% 34/103 [06:02<01:51,  1.62s/it]\u001b[A\n",
            " 34% 35/103 [06:04<01:52,  1.65s/it]\u001b[A\n",
            " 35% 36/103 [06:05<01:44,  1.57s/it]\u001b[A\n",
            " 36% 37/103 [06:07<01:48,  1.64s/it]\u001b[A\n",
            " 37% 38/103 [06:08<01:37,  1.51s/it]\u001b[A\n",
            " 38% 39/103 [06:10<01:43,  1.61s/it]\u001b[A\n",
            " 39% 40/103 [06:12<01:42,  1.63s/it]\u001b[A\n",
            " 40% 41/103 [06:13<01:36,  1.56s/it]\u001b[A\n",
            " 41% 42/103 [06:15<01:32,  1.51s/it]\u001b[A\n",
            " 42% 43/103 [06:16<01:28,  1.47s/it]\u001b[A\n",
            " 43% 44/103 [06:18<01:24,  1.44s/it]\u001b[A\n",
            " 44% 45/103 [06:19<01:27,  1.51s/it]\u001b[A\n",
            " 45% 46/103 [06:21<01:23,  1.46s/it]\u001b[A\n",
            " 46% 47/103 [06:22<01:19,  1.42s/it]\u001b[A\n",
            " 47% 48/103 [06:24<01:22,  1.50s/it]\u001b[A\n",
            " 48% 49/103 [06:25<01:18,  1.45s/it]\u001b[A\n",
            " 49% 50/103 [06:26<01:16,  1.44s/it]\u001b[A\n",
            " 50% 51/103 [06:28<01:18,  1.51s/it]\u001b[A\n",
            " 50% 52/103 [06:29<01:16,  1.50s/it]\u001b[A\n",
            " 51% 53/103 [06:31<01:14,  1.49s/it]\u001b[A\n",
            " 52% 54/103 [06:33<01:15,  1.54s/it]\u001b[A\n",
            " 53% 55/103 [06:34<01:12,  1.51s/it]\u001b[A\n",
            " 54% 56/103 [06:35<01:09,  1.47s/it]\u001b[A\n",
            " 55% 57/103 [06:37<01:10,  1.54s/it]\u001b[A\n",
            " 56% 58/103 [06:38<01:05,  1.46s/it]\u001b[A\n",
            " 57% 59/103 [06:40<01:04,  1.46s/it]\u001b[A\n",
            " 58% 60/103 [06:41<01:01,  1.44s/it]\u001b[A\n",
            " 59% 61/103 [06:43<00:59,  1.42s/it]\u001b[A\n",
            " 60% 62/103 [06:44<00:56,  1.37s/it]\u001b[A\n",
            " 61% 63/103 [06:45<00:54,  1.36s/it]\u001b[A\n",
            " 62% 64/103 [06:47<00:54,  1.39s/it]\u001b[A\n",
            " 63% 65/103 [06:48<00:57,  1.50s/it]\u001b[A\n",
            " 64% 66/103 [06:50<00:53,  1.45s/it]\u001b[A\n",
            " 65% 67/103 [06:51<00:53,  1.48s/it]\u001b[A\n",
            " 66% 68/103 [06:53<00:50,  1.46s/it]\u001b[A\n",
            " 67% 69/103 [06:54<00:47,  1.40s/it]\u001b[A\n",
            " 68% 70/103 [06:55<00:47,  1.42s/it]\u001b[A\n",
            " 69% 71/103 [06:57<00:48,  1.50s/it]\u001b[A\n",
            " 70% 72/103 [06:59<00:47,  1.54s/it]\u001b[A\n",
            " 71% 73/103 [07:00<00:44,  1.48s/it]\u001b[A\n",
            " 72% 74/103 [07:01<00:41,  1.43s/it]\u001b[A\n",
            " 73% 75/103 [07:03<00:38,  1.38s/it]\u001b[A\n",
            " 74% 76/103 [07:04<00:36,  1.35s/it]\u001b[A\n",
            " 75% 77/103 [07:06<00:37,  1.42s/it]\u001b[A\n",
            " 76% 78/103 [07:08<00:42,  1.68s/it]\u001b[A\n",
            " 77% 79/103 [07:09<00:39,  1.64s/it]\u001b[A\n",
            " 78% 80/103 [07:11<00:34,  1.52s/it]\u001b[A\n",
            " 79% 81/103 [07:12<00:35,  1.62s/it]\u001b[A\n",
            " 80% 82/103 [07:14<00:32,  1.54s/it]\u001b[A\n",
            " 81% 83/103 [07:15<00:30,  1.52s/it]\u001b[A\n",
            " 82% 84/103 [07:17<00:29,  1.56s/it]\u001b[A\n",
            " 83% 85/103 [07:18<00:27,  1.55s/it]\u001b[A\n",
            " 83% 86/103 [07:20<00:27,  1.59s/it]\u001b[A\n",
            " 84% 87/103 [07:22<00:26,  1.65s/it]\u001b[A\n",
            " 85% 88/103 [07:23<00:23,  1.59s/it]\u001b[A\n",
            " 86% 89/103 [07:25<00:21,  1.55s/it]\u001b[A\n",
            " 87% 90/103 [07:26<00:19,  1.48s/it]\u001b[A\n",
            " 88% 91/103 [07:28<00:18,  1.51s/it]\u001b[A\n",
            " 89% 92/103 [07:29<00:16,  1.48s/it]\u001b[A\n",
            " 90% 93/103 [07:31<00:14,  1.48s/it]\u001b[A\n",
            " 91% 94/103 [07:32<00:12,  1.43s/it]\u001b[A\n",
            " 92% 95/103 [07:34<00:12,  1.51s/it]\u001b[A\n",
            " 93% 96/103 [07:35<00:10,  1.54s/it]\u001b[A\n",
            " 94% 97/103 [07:37<00:08,  1.50s/it]\u001b[A\n",
            " 95% 98/103 [07:38<00:07,  1.44s/it]\u001b[A\n",
            " 96% 99/103 [07:39<00:05,  1.36s/it]\u001b[A\n",
            " 97% 100/103 [07:41<00:04,  1.43s/it]\u001b[A\n",
            " 98% 101/103 [07:42<00:02,  1.46s/it]\u001b[A\n",
            " 99% 102/103 [07:44<00:01,  1.59s/it]\u001b[A\n",
            "100% 103/103 [07:45<00:00,  1.30s/it]\u001b[A\n",
            "Epoch:4    | validation_loss:0.1092\n",
            "\n",
            "rouge1:0.4169| rouge2:0.1946| rougeL:0.3502| rougeLsum:0.3500\n",
            "\n",
            "=============================End Validation for fine tune Epoch: 4==================================\n",
            "\n",
            "==============================saving model for fine tune: 5==================================\n",
            "\n",
            "\n",
            "100% 103/103 [07:56<00:00,  4.62s/it]\n",
            "\n",
            "Epoch:5    | Batch:0    | Gtrain_loss:0.1283| Dtrain_loss:0.3748|0.4893\n",
            "\n",
            " discrimnator prediction: 68.72%| 77.07%\n",
            " 52% 480/920 [1:12:28<25:15,  3.44s/it]\n",
            "Epoch:5    | Batch:20   | Gtrain_loss:0.1567| Dtrain_loss:0.1125|0.3191\n",
            "\n",
            " discrimnator prediction: 75.86%| 77.56%\n",
            " 54% 500/920 [1:13:38<25:35,  3.66s/it]\n",
            "Epoch:5    | Batch:40   | Gtrain_loss:0.1120| Dtrain_loss:0.3067|0.5422\n",
            "\n",
            " discrimnator prediction: 71.98%| 77.98%\n",
            " 57% 520/920 [1:14:46<21:51,  3.28s/it]\n",
            "Epoch:5    | Batch:60   | Gtrain_loss:0.1232| Dtrain_loss:0.9566|0.0461\n",
            "\n",
            " discrimnator prediction: 77.79%| 83.91%\n",
            " 59% 540/920 [1:15:51<20:26,  3.23s/it]\n",
            "Epoch:5    | Batch:80   | Gtrain_loss:0.1419| Dtrain_loss:0.1897|0.5284\n",
            "\n",
            " discrimnator prediction: 80.68%| 79.71%\n",
            " 60% 552/920 [1:16:32<20:14,  3.30s/it]\n",
            "============================Start Validation for fine tune Epoch: 5================================\n",
            "\n",
            "\n",
            "  1% 1/103 [05:12<8:51:13, 312.49s/it]\u001b[A\u001b[A\n",
            "\n",
            "  2% 2/103 [05:13<3:38:04, 129.55s/it]\u001b[A\u001b[A\n",
            "\n",
            "  3% 3/103 [05:15<1:58:38, 71.18s/it] \u001b[A\u001b[A\n",
            "\n",
            "  4% 4/103 [05:17<1:12:05, 43.69s/it]\u001b[A\u001b[A\n",
            "\n",
            "  5% 5/103 [05:18<46:23, 28.40s/it]  \u001b[A\u001b[A\n",
            "\n",
            "  6% 6/103 [05:19<31:00, 19.18s/it]\u001b[A\u001b[A\n",
            "\n",
            "  7% 7/103 [05:21<21:22, 13.36s/it]\u001b[A\u001b[A\n",
            "\n",
            "  8% 8/103 [05:23<15:26,  9.75s/it]\u001b[A\u001b[A\n",
            "\n",
            "  9% 9/103 [05:24<11:08,  7.11s/it]\u001b[A\u001b[A\n",
            "\n",
            " 10% 10/103 [05:26<08:24,  5.43s/it]\u001b[A\u001b[A\n",
            "\n",
            " 11% 11/103 [05:27<06:26,  4.20s/it]\u001b[A\u001b[A\n",
            "\n",
            " 12% 12/103 [05:28<04:58,  3.28s/it]\u001b[A\u001b[A\n",
            "\n",
            " 13% 13/103 [05:30<04:03,  2.70s/it]\u001b[A\u001b[A\n",
            "\n",
            " 14% 14/103 [05:31<03:29,  2.35s/it]\u001b[A\u001b[A\n",
            "\n",
            " 15% 15/103 [05:33<03:08,  2.14s/it]\u001b[A\u001b[A\n",
            "\n",
            " 16% 16/103 [05:34<02:45,  1.91s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17% 17/103 [05:36<02:34,  1.80s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17% 18/103 [05:37<02:22,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 18% 19/103 [05:39<02:13,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 19% 20/103 [05:40<02:08,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 20% 21/103 [05:41<02:04,  1.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 21% 22/103 [05:43<01:57,  1.45s/it]\u001b[A\u001b[A\n",
            "\n",
            " 22% 23/103 [05:44<01:53,  1.42s/it]\u001b[A\u001b[A\n",
            "\n",
            " 23% 24/103 [05:46<01:57,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 24% 25/103 [05:47<01:50,  1.42s/it]\u001b[A\u001b[A\n",
            "\n",
            " 25% 26/103 [05:48<01:46,  1.39s/it]\u001b[A\u001b[A\n",
            "\n",
            " 26% 27/103 [05:50<01:48,  1.42s/it]\u001b[A\u001b[A\n",
            "\n",
            " 27% 28/103 [05:52<01:55,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 28% 29/103 [05:53<01:53,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 29% 30/103 [05:55<01:50,  1.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 30% 31/103 [05:56<01:49,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 31% 32/103 [05:58<01:44,  1.47s/it]\u001b[A\u001b[A\n",
            "\n",
            " 32% 33/103 [05:59<01:45,  1.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33% 34/103 [06:01<01:53,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 34% 35/103 [06:03<01:47,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 35% 36/103 [06:04<01:43,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 36% 37/103 [06:06<01:43,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 37% 38/103 [06:07<01:36,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 38% 39/103 [06:08<01:37,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 39% 40/103 [06:10<01:37,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 40% 41/103 [06:11<01:32,  1.49s/it]\u001b[A\u001b[A\n",
            "\n",
            " 41% 42/103 [06:13<01:28,  1.46s/it]\u001b[A\u001b[A\n",
            "\n",
            " 42% 43/103 [06:14<01:30,  1.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 43% 44/103 [06:16<01:25,  1.44s/it]\u001b[A\u001b[A\n",
            "\n",
            " 44% 45/103 [06:18<01:29,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 45% 46/103 [06:19<01:26,  1.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 46% 47/103 [06:20<01:21,  1.45s/it]\u001b[A\u001b[A\n",
            "\n",
            " 47% 48/103 [06:22<01:22,  1.50s/it]\u001b[A\u001b[A\n",
            "\n",
            " 48% 49/103 [06:24<01:23,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 49% 50/103 [06:25<01:18,  1.49s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50% 51/103 [06:27<01:21,  1.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50% 52/103 [06:28<01:17,  1.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 51% 53/103 [06:30<01:16,  1.53s/it]\u001b[A\u001b[A\n",
            "\n",
            " 52% 54/103 [06:31<01:15,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 53% 55/103 [06:33<01:13,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 54% 56/103 [06:34<01:10,  1.50s/it]\u001b[A\u001b[A\n",
            "\n",
            " 55% 57/103 [06:36<01:11,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 56% 58/103 [06:37<01:05,  1.45s/it]\u001b[A\u001b[A\n",
            "\n",
            " 57% 59/103 [06:38<01:02,  1.42s/it]\u001b[A\u001b[A\n",
            "\n",
            " 58% 60/103 [06:40<01:00,  1.41s/it]\u001b[A\u001b[A\n",
            "\n",
            " 59% 61/103 [06:41<00:58,  1.39s/it]\u001b[A\u001b[A\n",
            "\n",
            " 60% 62/103 [06:42<00:55,  1.36s/it]\u001b[A\u001b[A\n",
            "\n",
            " 61% 63/103 [06:43<00:50,  1.27s/it]\u001b[A\u001b[A\n",
            "\n",
            " 62% 64/103 [06:45<00:51,  1.33s/it]\u001b[A\u001b[A\n",
            "\n",
            " 63% 65/103 [06:47<00:56,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 64% 66/103 [06:48<00:53,  1.43s/it]\u001b[A\u001b[A\n",
            "\n",
            " 65% 67/103 [06:49<00:51,  1.43s/it]\u001b[A\u001b[A\n",
            "\n",
            " 66% 68/103 [06:51<00:50,  1.44s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67% 69/103 [06:52<00:46,  1.38s/it]\u001b[A\u001b[A\n",
            "\n",
            " 68% 70/103 [06:54<00:46,  1.41s/it]\u001b[A\u001b[A\n",
            "\n",
            " 69% 71/103 [06:55<00:47,  1.49s/it]\u001b[A\u001b[A\n",
            "\n",
            " 70% 72/103 [06:57<00:46,  1.50s/it]\u001b[A\u001b[A\n",
            "\n",
            " 71% 73/103 [06:58<00:43,  1.44s/it]\u001b[A\u001b[A\n",
            "\n",
            " 72% 74/103 [06:59<00:40,  1.41s/it]\u001b[A\u001b[A\n",
            "\n",
            " 73% 75/103 [07:01<00:40,  1.43s/it]\u001b[A\u001b[A\n",
            "\n",
            " 74% 76/103 [07:02<00:37,  1.39s/it]\u001b[A\u001b[A\n",
            "\n",
            " 75% 77/103 [07:04<00:36,  1.40s/it]\u001b[A\u001b[A\n",
            "\n",
            " 76% 78/103 [07:06<00:41,  1.65s/it]\u001b[A\u001b[A\n",
            "\n",
            " 77% 79/103 [07:08<00:41,  1.74s/it]\u001b[A\u001b[A\n",
            "\n",
            " 78% 80/103 [07:09<00:36,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 79% 81/103 [07:11<00:36,  1.66s/it]\u001b[A\u001b[A\n",
            "\n",
            " 80% 82/103 [07:12<00:33,  1.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 81% 83/103 [07:14<00:30,  1.53s/it]\u001b[A\u001b[A\n",
            "\n",
            " 82% 84/103 [07:15<00:30,  1.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83% 85/103 [07:17<00:27,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83% 86/103 [07:18<00:26,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 84% 87/103 [07:20<00:25,  1.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 85% 88/103 [07:22<00:23,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 86% 89/103 [07:23<00:21,  1.53s/it]\u001b[A\u001b[A\n",
            "\n",
            " 87% 90/103 [07:24<00:18,  1.45s/it]\u001b[A\u001b[A\n",
            "\n",
            " 88% 91/103 [07:26<00:17,  1.46s/it]\u001b[A\u001b[A\n",
            "\n",
            " 89% 92/103 [07:28<00:17,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 90% 93/103 [07:29<00:15,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 91% 94/103 [07:30<00:13,  1.46s/it]\u001b[A\u001b[A\n",
            "\n",
            " 92% 95/103 [07:32<00:12,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 93% 96/103 [07:34<00:11,  1.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 94% 97/103 [07:35<00:09,  1.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 95% 98/103 [07:36<00:07,  1.43s/it]\u001b[A\u001b[A\n",
            "\n",
            " 96% 99/103 [07:38<00:05,  1.34s/it]\u001b[A\u001b[A\n",
            "\n",
            " 97% 100/103 [07:39<00:04,  1.38s/it]\u001b[A\u001b[A\n",
            "\n",
            " 98% 101/103 [07:41<00:02,  1.44s/it]\u001b[A\u001b[A\n",
            "\n",
            " 99% 102/103 [07:42<00:01,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            "100% 103/103 [07:43<00:00,  1.27s/it]\u001b[A\u001b[A\n",
            "Epoch:5    | validation_loss:0.1049\n",
            "\n",
            "rouge1:0.4205| rouge2:0.1985| rougeL:0.3535| rougeLsum:0.3533\n",
            "\n",
            "=============================End Validation for fine tune Epoch: 5==================================\n",
            "\n",
            "==============================saving model for fine tune: 6==================================\n",
            "\n",
            "100% 103/103 [07:51<00:00,  4.58s/it]\n",
            "\n",
            "Epoch:6    | Batch:0    | Gtrain_loss:0.1112| Dtrain_loss:0.6624|0.1091\n",
            "\n",
            " discrimnator prediction: 77.62%| 75.15%\n",
            " 62% 572/920 [1:20:19<21:30,  3.71s/it]\n",
            "Epoch:6    | Batch:20   | Gtrain_loss:0.1332| Dtrain_loss:0.1878|0.2773\n",
            "\n",
            " discrimnator prediction: 78.97%| 82.76%\n",
            " 64% 592/920 [1:21:28<18:14,  3.34s/it]\n",
            "Epoch:6    | Batch:40   | Gtrain_loss:0.1069| Dtrain_loss:0.2157|0.4009\n",
            "\n",
            " discrimnator prediction: 81.56%| 77.82%\n",
            " 67% 612/920 [1:22:37<17:04,  3.33s/it]\n",
            "Epoch:6    | Batch:60   | Gtrain_loss:0.1165| Dtrain_loss:0.2576|0.0669\n",
            "\n",
            " discrimnator prediction: 81.97%| 79.22%\n",
            " 69% 632/920 [1:23:42<15:47,  3.29s/it]\n",
            "Epoch:6    | Batch:80   | Gtrain_loss:0.1315| Dtrain_loss:0.2019|0.3696\n",
            "\n",
            " discrimnator prediction: 77.79%| 78.50%\n",
            " 70% 644/920 [1:24:24<15:52,  3.45s/it]\n",
            "============================Start Validation for fine tune Epoch: 6================================\n",
            "\n",
            "  1% 1/103 [05:13<8:52:51, 313.45s/it]\u001b[A\n",
            "  2% 2/103 [05:14<3:38:46, 129.96s/it]\u001b[A\n",
            "  3% 3/103 [05:16<1:58:56, 71.36s/it] \u001b[A\n",
            "  4% 4/103 [05:18<1:12:13, 43.77s/it]\u001b[A\n",
            "  5% 5/103 [05:19<46:29, 28.46s/it]  \u001b[A\n",
            "  6% 6/103 [05:20<31:09, 19.28s/it]\u001b[A\n",
            "  7% 7/103 [05:22<21:29, 13.43s/it]\u001b[A\n",
            "  8% 8/103 [05:24<15:23,  9.72s/it]\u001b[A\n",
            "  9% 9/103 [05:25<11:09,  7.12s/it]\u001b[A\n",
            " 10% 10/103 [05:27<08:33,  5.52s/it]\u001b[A\n",
            " 11% 11/103 [05:28<06:30,  4.25s/it]\u001b[A\n",
            " 12% 12/103 [05:30<05:06,  3.37s/it]\u001b[A\n",
            " 13% 13/103 [05:31<04:11,  2.79s/it]\u001b[A\n",
            " 14% 14/103 [05:32<03:28,  2.34s/it]\u001b[A\n",
            " 15% 15/103 [05:34<03:12,  2.18s/it]\u001b[A\n",
            " 16% 16/103 [05:36<02:53,  1.99s/it]\u001b[A\n",
            " 17% 17/103 [05:37<02:38,  1.85s/it]\u001b[A\n",
            " 17% 18/103 [05:39<02:29,  1.76s/it]\u001b[A\n",
            " 18% 19/103 [05:40<02:24,  1.72s/it]\u001b[A\n",
            " 19% 20/103 [05:42<02:17,  1.65s/it]\u001b[A\n",
            " 20% 21/103 [05:43<02:08,  1.56s/it]\u001b[A\n",
            " 21% 22/103 [05:45<02:00,  1.48s/it]\u001b[A\n",
            " 22% 23/103 [05:46<01:59,  1.50s/it]\u001b[A\n",
            " 23% 24/103 [05:48<02:05,  1.59s/it]\u001b[A\n",
            " 24% 25/103 [05:49<01:55,  1.48s/it]\u001b[A\n",
            " 25% 26/103 [05:51<01:58,  1.54s/it]\u001b[A\n",
            " 26% 27/103 [05:52<01:57,  1.54s/it]\u001b[A\n",
            " 27% 28/103 [05:54<02:03,  1.65s/it]\u001b[A\n",
            " 28% 29/103 [05:56<02:02,  1.65s/it]\u001b[A\n",
            " 29% 30/103 [05:57<01:53,  1.56s/it]\u001b[A\n",
            " 30% 31/103 [05:59<01:54,  1.59s/it]\u001b[A\n",
            " 31% 32/103 [06:00<01:48,  1.53s/it]\u001b[A\n",
            " 32% 33/103 [06:02<01:49,  1.57s/it]\u001b[A\n",
            " 33% 34/103 [06:04<01:57,  1.70s/it]\u001b[A\n",
            " 34% 35/103 [06:05<01:51,  1.64s/it]\u001b[A\n",
            " 35% 36/103 [06:07<01:44,  1.56s/it]\u001b[A\n",
            " 36% 37/103 [06:09<01:45,  1.60s/it]\u001b[A\n",
            " 37% 38/103 [06:10<01:40,  1.54s/it]\u001b[A\n",
            " 38% 39/103 [06:12<01:42,  1.61s/it]\u001b[A\n",
            " 39% 40/103 [06:13<01:42,  1.63s/it]\u001b[A\n",
            " 40% 41/103 [06:15<01:39,  1.60s/it]\u001b[A\n",
            " 41% 42/103 [06:16<01:34,  1.54s/it]\u001b[A\n",
            " 42% 43/103 [06:18<01:40,  1.68s/it]\u001b[A\n",
            " 43% 44/103 [06:20<01:32,  1.57s/it]\u001b[A\n",
            " 44% 45/103 [06:21<01:34,  1.64s/it]\u001b[A\n",
            " 45% 46/103 [06:23<01:29,  1.58s/it]\u001b[A\n",
            " 46% 47/103 [06:24<01:24,  1.51s/it]\u001b[A\n",
            " 47% 48/103 [06:26<01:27,  1.59s/it]\u001b[A\n",
            " 48% 49/103 [06:28<01:25,  1.59s/it]\u001b[A\n",
            " 49% 50/103 [06:29<01:22,  1.55s/it]\u001b[A\n",
            " 50% 51/103 [06:31<01:26,  1.66s/it]\u001b[A\n",
            " 50% 52/103 [06:32<01:22,  1.62s/it]\u001b[A\n",
            " 51% 53/103 [06:34<01:21,  1.63s/it]\u001b[A\n",
            " 52% 54/103 [06:36<01:17,  1.59s/it]\u001b[A\n",
            " 53% 55/103 [06:37<01:12,  1.51s/it]\u001b[A\n",
            " 54% 56/103 [06:38<01:09,  1.49s/it]\u001b[A\n",
            " 55% 57/103 [06:40<01:12,  1.58s/it]\u001b[A\n",
            " 56% 58/103 [06:42<01:08,  1.53s/it]\u001b[A\n",
            " 57% 59/103 [06:43<01:07,  1.54s/it]\u001b[A\n",
            " 58% 60/103 [06:45<01:04,  1.49s/it]\u001b[A\n",
            " 59% 61/103 [06:46<01:00,  1.43s/it]\u001b[A\n",
            " 60% 62/103 [06:47<00:58,  1.43s/it]\u001b[A\n",
            " 61% 63/103 [06:49<00:56,  1.41s/it]\u001b[A\n",
            " 62% 64/103 [06:50<00:56,  1.46s/it]\u001b[A\n",
            " 63% 65/103 [06:52<00:59,  1.56s/it]\u001b[A\n",
            " 64% 66/103 [06:53<00:55,  1.49s/it]\u001b[A\n",
            " 65% 67/103 [06:55<00:53,  1.48s/it]\u001b[A\n",
            " 66% 68/103 [06:56<00:52,  1.50s/it]\u001b[A\n",
            " 67% 69/103 [06:58<00:51,  1.51s/it]\u001b[A\n",
            " 68% 70/103 [06:59<00:50,  1.54s/it]\u001b[A\n",
            " 69% 71/103 [07:01<00:50,  1.58s/it]\u001b[A\n",
            " 70% 72/103 [07:03<00:49,  1.61s/it]\u001b[A\n",
            " 71% 73/103 [07:04<00:45,  1.50s/it]\u001b[A\n",
            " 72% 74/103 [07:06<00:45,  1.57s/it]\u001b[A\n",
            " 73% 75/103 [07:07<00:43,  1.55s/it]\u001b[A\n",
            " 74% 76/103 [07:09<00:40,  1.49s/it]\u001b[A\n",
            " 75% 77/103 [07:10<00:38,  1.49s/it]\u001b[A\n",
            " 76% 78/103 [07:12<00:43,  1.72s/it]\u001b[A\n",
            " 77% 79/103 [07:14<00:42,  1.76s/it]\u001b[A\n",
            " 78% 80/103 [07:15<00:36,  1.61s/it]\u001b[A\n",
            " 79% 81/103 [07:17<00:37,  1.72s/it]\u001b[A\n",
            " 80% 82/103 [07:19<00:34,  1.62s/it]\u001b[A\n",
            " 81% 83/103 [07:21<00:33,  1.66s/it]\u001b[A\n",
            " 82% 84/103 [07:22<00:31,  1.65s/it]\u001b[A\n",
            " 83% 85/103 [07:24<00:29,  1.62s/it]\u001b[A\n",
            " 83% 86/103 [07:25<00:27,  1.62s/it]\u001b[A\n",
            " 84% 87/103 [07:27<00:25,  1.57s/it]\u001b[A\n",
            " 85% 88/103 [07:28<00:23,  1.56s/it]\u001b[A\n",
            " 86% 89/103 [07:30<00:21,  1.55s/it]\u001b[A\n",
            " 87% 90/103 [07:31<00:20,  1.55s/it]\u001b[A\n",
            " 88% 91/103 [07:33<00:18,  1.52s/it]\u001b[A\n",
            " 89% 92/103 [07:35<00:17,  1.56s/it]\u001b[A\n",
            " 90% 93/103 [07:36<00:15,  1.59s/it]\u001b[A\n",
            " 91% 94/103 [07:37<00:13,  1.48s/it]\u001b[A\n",
            " 92% 95/103 [07:39<00:12,  1.60s/it]\u001b[A\n",
            " 93% 96/103 [07:41<00:11,  1.66s/it]\u001b[A\n",
            " 94% 97/103 [07:43<00:09,  1.60s/it]\u001b[A\n",
            " 95% 98/103 [07:44<00:07,  1.58s/it]\u001b[A\n",
            " 96% 99/103 [07:45<00:05,  1.48s/it]\u001b[A\n",
            " 97% 100/103 [07:47<00:04,  1.64s/it]\u001b[A\n",
            " 98% 101/103 [07:49<00:03,  1.60s/it]\u001b[A\n",
            " 99% 102/103 [07:51<00:01,  1.67s/it]\u001b[A\n",
            "100% 103/103 [07:51<00:00,  1.36s/it]\u001b[A\n",
            "Epoch:6    | validation_loss:0.1027\n",
            "\n",
            "rouge1:0.4308| rouge2:0.2011| rougeL:0.3571| rougeLsum:0.3572\n",
            "\n",
            "=============================End Validation for fine tune Epoch: 6==================================\n",
            "\n",
            "==============================saving model for fine tune: 7==================================\n",
            "\n",
            "\n",
            "100% 103/103 [07:59<00:00,  4.66s/it]\n",
            "\n",
            "Epoch:7    | Batch:0    | Gtrain_loss:0.1059| Dtrain_loss:0.2380|0.4514\n",
            "\n",
            " discrimnator prediction: 83.56%| 79.95%\n",
            " 72% 664/920 [1:28:18<14:37,  3.43s/it]\n",
            "Epoch:7    | Batch:20   | Gtrain_loss:0.1286| Dtrain_loss:0.2570|0.1853\n",
            "\n",
            " discrimnator prediction: 80.74%| 81.00%\n",
            " 74% 684/920 [1:29:30<15:07,  3.85s/it]\n",
            "Epoch:7    | Batch:40   | Gtrain_loss:0.0872| Dtrain_loss:0.2271|0.0712\n",
            "\n",
            " discrimnator prediction: 81.66%| 81.81%\n",
            " 77% 704/920 [1:30:38<12:03,  3.35s/it]\n",
            "Epoch:7    | Batch:60   | Gtrain_loss:0.1073| Dtrain_loss:0.1509|0.2939\n",
            "\n",
            " discrimnator prediction: 83.76%| 79.15%\n",
            " 79% 724/920 [1:31:42<10:43,  3.28s/it]\n",
            "Epoch:7    | Batch:80   | Gtrain_loss:0.1272| Dtrain_loss:0.2221|0.3145\n",
            "\n",
            " discrimnator prediction: 81.32%| 85.16%\n",
            " 80% 736/920 [1:32:25<10:32,  3.44s/it]\n",
            "============================Start Validation for fine tune Epoch: 7================================\n",
            "\n",
            "\n",
            "  1% 1/103 [05:14<8:54:22, 314.34s/it]\u001b[A\u001b[A\n",
            "\n",
            "  2% 2/103 [05:15<3:39:16, 130.26s/it]\u001b[A\u001b[A\n",
            "\n",
            "  3% 3/103 [05:17<1:59:01, 71.41s/it] \u001b[A\u001b[A\n",
            "\n",
            "  4% 4/103 [05:18<1:12:24, 43.89s/it]\u001b[A\u001b[A\n",
            "\n",
            "  5% 5/103 [05:20<46:36, 28.54s/it]  \u001b[A\u001b[A\n",
            "\n",
            "  6% 6/103 [05:21<31:17, 19.36s/it]\u001b[A\u001b[A\n",
            "\n",
            "  7% 7/103 [05:23<21:34, 13.48s/it]\u001b[A\u001b[A\n",
            "\n",
            "  8% 8/103 [05:24<15:29,  9.78s/it]\u001b[A\u001b[A\n",
            "\n",
            "  9% 9/103 [05:26<11:12,  7.15s/it]\u001b[A\u001b[A\n",
            "\n",
            " 10% 10/103 [05:28<08:29,  5.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 11% 11/103 [05:29<06:27,  4.21s/it]\u001b[A\u001b[A\n",
            "\n",
            " 12% 12/103 [05:30<05:07,  3.38s/it]\u001b[A\u001b[A\n",
            "\n",
            " 13% 13/103 [05:32<04:11,  2.79s/it]\u001b[A\u001b[A\n",
            "\n",
            " 14% 14/103 [05:33<03:34,  2.41s/it]\u001b[A\u001b[A\n",
            "\n",
            " 15% 15/103 [05:35<03:13,  2.19s/it]\u001b[A\u001b[A\n",
            "\n",
            " 16% 16/103 [05:36<02:48,  1.94s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17% 17/103 [05:38<02:37,  1.83s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17% 18/103 [05:39<02:25,  1.71s/it]\u001b[A\u001b[A\n",
            "\n",
            " 18% 19/103 [05:41<02:20,  1.67s/it]\u001b[A\u001b[A\n",
            "\n",
            " 19% 20/103 [05:43<02:16,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 20% 21/103 [05:44<02:07,  1.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 21% 22/103 [05:45<02:04,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 22% 23/103 [05:47<02:07,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 23% 24/103 [05:49<02:11,  1.66s/it]\u001b[A\u001b[A\n",
            "\n",
            " 24% 25/103 [05:50<02:00,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 25% 26/103 [05:52<02:05,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 26% 27/103 [05:53<01:59,  1.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 27% 28/103 [05:55<02:06,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 28% 29/103 [05:57<02:10,  1.77s/it]\u001b[A\u001b[A\n",
            "\n",
            " 29% 30/103 [05:59<02:02,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 30% 31/103 [06:00<01:59,  1.66s/it]\u001b[A\u001b[A\n",
            "\n",
            " 31% 32/103 [06:02<01:51,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 32% 33/103 [06:04<01:55,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33% 34/103 [06:06<02:03,  1.79s/it]\u001b[A\u001b[A\n",
            "\n",
            " 34% 35/103 [06:07<01:56,  1.71s/it]\u001b[A\u001b[A\n",
            "\n",
            " 35% 36/103 [06:09<01:48,  1.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 36% 37/103 [06:10<01:48,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 37% 38/103 [06:12<01:41,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 38% 39/103 [06:14<01:47,  1.67s/it]\u001b[A\u001b[A\n",
            "\n",
            " 39% 40/103 [06:16<01:47,  1.71s/it]\u001b[A\u001b[A\n",
            "\n",
            " 40% 41/103 [06:17<01:44,  1.69s/it]\u001b[A\u001b[A\n",
            "\n",
            " 41% 42/103 [06:19<01:38,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 42% 43/103 [06:20<01:39,  1.65s/it]\u001b[A\u001b[A\n",
            "\n",
            " 43% 44/103 [06:22<01:31,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 44% 45/103 [06:23<01:34,  1.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 45% 46/103 [06:25<01:32,  1.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 46% 47/103 [06:26<01:26,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 47% 48/103 [06:28<01:27,  1.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 48% 49/103 [06:30<01:27,  1.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 49% 50/103 [06:31<01:22,  1.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50% 51/103 [06:33<01:26,  1.65s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50% 52/103 [06:34<01:19,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 51% 53/103 [06:36<01:20,  1.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 52% 54/103 [06:37<01:14,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 53% 55/103 [06:39<01:09,  1.44s/it]\u001b[A\u001b[A\n",
            "\n",
            " 54% 56/103 [06:40<01:10,  1.50s/it]\u001b[A\u001b[A\n",
            "\n",
            " 55% 57/103 [06:42<01:13,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 56% 58/103 [06:44<01:09,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 57% 59/103 [06:45<01:08,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 58% 60/103 [06:47<01:09,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 59% 61/103 [06:48<01:05,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 60% 62/103 [06:50<01:02,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 61% 63/103 [06:51<00:58,  1.47s/it]\u001b[A\u001b[A\n",
            "\n",
            " 62% 64/103 [06:52<00:56,  1.44s/it]\u001b[A\u001b[A\n",
            "\n",
            " 63% 65/103 [06:54<01:01,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 64% 66/103 [06:56<00:56,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 65% 67/103 [06:57<00:53,  1.49s/it]\u001b[A\u001b[A\n",
            "\n",
            " 66% 68/103 [06:59<00:52,  1.49s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67% 69/103 [07:00<00:50,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 68% 70/103 [07:02<00:48,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 69% 71/103 [07:03<00:48,  1.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 70% 72/103 [07:05<00:47,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 71% 73/103 [07:06<00:44,  1.50s/it]\u001b[A\u001b[A\n",
            "\n",
            " 72% 74/103 [07:08<00:42,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 73% 75/103 [07:09<00:42,  1.50s/it]\u001b[A\u001b[A\n",
            "\n",
            " 74% 76/103 [07:11<00:38,  1.44s/it]\u001b[A\u001b[A\n",
            "\n",
            " 75% 77/103 [07:12<00:39,  1.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 76% 78/103 [07:15<00:44,  1.76s/it]\u001b[A\u001b[A\n",
            "\n",
            " 77% 79/103 [07:17<00:44,  1.85s/it]\u001b[A\u001b[A\n",
            "\n",
            " 78% 80/103 [07:18<00:38,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 79% 81/103 [07:20<00:39,  1.79s/it]\u001b[A\u001b[A\n",
            "\n",
            " 80% 82/103 [07:21<00:35,  1.67s/it]\u001b[A\u001b[A\n",
            "\n",
            " 81% 83/103 [07:23<00:32,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 82% 84/103 [07:25<00:31,  1.66s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83% 85/103 [07:26<00:28,  1.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83% 86/103 [07:28<00:26,  1.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 84% 87/103 [07:29<00:26,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 85% 88/103 [07:31<00:23,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 86% 89/103 [07:32<00:21,  1.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 87% 90/103 [07:34<00:19,  1.53s/it]\u001b[A\u001b[A\n",
            "\n",
            " 88% 91/103 [07:36<00:19,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 89% 92/103 [07:37<00:17,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 90% 93/103 [07:39<00:16,  1.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 91% 94/103 [07:40<00:13,  1.53s/it]\u001b[A\u001b[A\n",
            "\n",
            " 92% 95/103 [07:42<00:13,  1.69s/it]\u001b[A\u001b[A\n",
            "\n",
            " 93% 96/103 [07:44<00:12,  1.74s/it]\u001b[A\u001b[A\n",
            "\n",
            " 94% 97/103 [07:45<00:09,  1.63s/it]\u001b[A\u001b[A\n",
            "\n",
            " 95% 98/103 [07:47<00:07,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 96% 99/103 [07:48<00:05,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 97% 100/103 [07:50<00:04,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 98% 101/103 [07:51<00:03,  1.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 99% 102/103 [07:53<00:01,  1.66s/it]\u001b[A\u001b[A\n",
            "\n",
            "100% 103/103 [07:54<00:00,  1.37s/it]\u001b[A\u001b[A\n",
            "Epoch:7    | validation_loss:0.1015\n",
            "\n",
            "rouge1:0.4325| rouge2:0.2014| rougeL:0.3585| rougeLsum:0.3585\n",
            "\n",
            "=============================End Validation for fine tune Epoch: 7==================================\n",
            "\n",
            "==============================saving model for fine tune: 8==================================\n",
            "\n",
            "100% 103/103 [08:02<00:00,  4.69s/it]\n",
            "\n",
            "Epoch:8    | Batch:0    | Gtrain_loss:0.0968| Dtrain_loss:0.2055|0.6469\n",
            "\n",
            " discrimnator prediction: 82.65%| 77.12%\n",
            " 82% 756/920 [1:36:24<10:05,  3.69s/it]\n",
            "Epoch:8    | Batch:20   | Gtrain_loss:0.1158| Dtrain_loss:0.3575|0.1252\n",
            "\n",
            " discrimnator prediction: 83.21%| 74.42%\n",
            " 84% 776/920 [1:37:35<08:34,  3.57s/it]\n",
            "Epoch:8    | Batch:40   | Gtrain_loss:0.0906| Dtrain_loss:0.1683|0.3915\n",
            "\n",
            " discrimnator prediction: 78.57%| 86.65%\n",
            " 87% 796/920 [1:38:42<06:42,  3.25s/it]\n",
            "Epoch:8    | Batch:60   | Gtrain_loss:0.0985| Dtrain_loss:0.1233|0.4066\n",
            "\n",
            " discrimnator prediction: 86.69%| 82.66%\n",
            " 89% 816/920 [1:39:48<05:42,  3.29s/it]\n",
            "Epoch:8    | Batch:80   | Gtrain_loss:0.1241| Dtrain_loss:0.0519|0.0549\n",
            "\n",
            " discrimnator prediction: 86.78%| 86.80%\n",
            " 90% 828/920 [1:40:30<05:11,  3.39s/it]\n",
            "============================Start Validation for fine tune Epoch: 8================================\n",
            "\n",
            "  1% 1/103 [05:16<8:58:05, 316.52s/it]\u001b[A\n",
            "  2% 2/103 [05:18<3:41:01, 131.30s/it]\u001b[A\n",
            "  3% 3/103 [05:19<1:59:56, 71.97s/it] \u001b[A\n",
            "  4% 4/103 [05:21<1:13:11, 44.36s/it]\u001b[A\n",
            "  5% 5/103 [05:22<47:04, 28.82s/it]  \u001b[A\n",
            "  6% 6/103 [05:24<31:37, 19.56s/it]\u001b[A\n",
            "  7% 7/103 [05:25<21:47, 13.62s/it]\u001b[A\n",
            "  8% 8/103 [05:27<15:43,  9.93s/it]\u001b[A\n",
            "  9% 9/103 [05:29<11:20,  7.24s/it]\u001b[A\n",
            " 10% 10/103 [05:30<08:36,  5.55s/it]\u001b[A\n",
            " 11% 11/103 [05:32<06:32,  4.26s/it]\u001b[A\n",
            " 12% 12/103 [05:33<05:04,  3.34s/it]\u001b[A\n",
            " 13% 13/103 [05:34<04:08,  2.76s/it]\u001b[A\n",
            " 14% 14/103 [05:36<03:33,  2.40s/it]\u001b[A\n",
            " 15% 15/103 [05:38<03:15,  2.22s/it]\u001b[A\n",
            " 16% 16/103 [05:39<02:53,  1.99s/it]\u001b[A\n",
            " 17% 17/103 [05:41<02:41,  1.88s/it]\u001b[A\n",
            " 17% 18/103 [05:42<02:29,  1.76s/it]\u001b[A\n",
            " 18% 19/103 [05:44<02:20,  1.68s/it]\u001b[A\n",
            " 19% 20/103 [05:45<02:14,  1.62s/it]\u001b[A\n",
            " 20% 21/103 [05:47<02:06,  1.54s/it]\u001b[A\n",
            " 21% 22/103 [05:48<02:04,  1.54s/it]\u001b[A\n",
            " 22% 23/103 [05:50<02:08,  1.61s/it]\u001b[A\n",
            " 23% 24/103 [05:52<02:14,  1.70s/it]\u001b[A\n",
            " 24% 25/103 [05:53<02:04,  1.60s/it]\u001b[A\n",
            " 25% 26/103 [05:55<02:02,  1.59s/it]\u001b[A\n",
            " 26% 27/103 [05:56<02:00,  1.59s/it]\u001b[A\n",
            " 27% 28/103 [05:58<02:05,  1.67s/it]\u001b[A\n",
            " 28% 29/103 [06:00<01:58,  1.60s/it]\u001b[A\n",
            " 29% 30/103 [06:01<01:55,  1.58s/it]\u001b[A\n",
            " 30% 31/103 [06:03<02:01,  1.68s/it]\u001b[A\n",
            " 31% 32/103 [06:04<01:51,  1.57s/it]\u001b[A\n",
            " 32% 33/103 [06:06<01:53,  1.62s/it]\u001b[A\n",
            " 33% 34/103 [06:08<02:04,  1.80s/it]\u001b[A\n",
            " 34% 35/103 [06:10<01:53,  1.67s/it]\u001b[A\n",
            " 35% 36/103 [06:11<01:47,  1.60s/it]\u001b[A\n",
            " 36% 37/103 [06:13<01:47,  1.63s/it]\u001b[A\n",
            " 37% 38/103 [06:14<01:42,  1.58s/it]\u001b[A\n",
            " 38% 39/103 [06:16<01:45,  1.65s/it]\u001b[A\n",
            " 39% 40/103 [06:18<01:44,  1.65s/it]\u001b[A\n",
            " 40% 41/103 [06:19<01:39,  1.61s/it]\u001b[A\n",
            " 41% 42/103 [06:21<01:34,  1.55s/it]\u001b[A\n",
            " 42% 43/103 [06:23<01:36,  1.61s/it]\u001b[A\n",
            " 43% 44/103 [06:24<01:30,  1.53s/it]\u001b[A\n",
            " 44% 45/103 [06:26<01:30,  1.56s/it]\u001b[A\n",
            " 45% 46/103 [06:27<01:26,  1.51s/it]\u001b[A\n",
            " 46% 47/103 [06:28<01:23,  1.49s/it]\u001b[A\n",
            " 47% 48/103 [06:30<01:26,  1.57s/it]\u001b[A\n",
            " 48% 49/103 [06:32<01:27,  1.62s/it]\u001b[A\n",
            " 49% 50/103 [06:33<01:20,  1.52s/it]\u001b[A\n",
            " 50% 51/103 [06:35<01:26,  1.66s/it]\u001b[A\n",
            " 50% 52/103 [06:36<01:19,  1.56s/it]\u001b[A\n",
            " 51% 53/103 [06:38<01:18,  1.58s/it]\u001b[A\n",
            " 52% 54/103 [06:39<01:14,  1.51s/it]\u001b[A\n",
            " 53% 55/103 [06:41<01:09,  1.44s/it]\u001b[A\n",
            " 54% 56/103 [06:42<01:08,  1.45s/it]\u001b[A\n",
            " 55% 57/103 [06:44<01:11,  1.56s/it]\u001b[A\n",
            " 56% 58/103 [06:45<01:08,  1.51s/it]\u001b[A\n",
            " 57% 59/103 [06:47<01:04,  1.46s/it]\u001b[A\n",
            " 58% 60/103 [06:48<01:01,  1.43s/it]\u001b[A\n",
            " 59% 61/103 [06:49<00:59,  1.41s/it]\u001b[A\n",
            " 60% 62/103 [06:51<00:57,  1.40s/it]\u001b[A\n",
            " 61% 63/103 [06:52<00:54,  1.37s/it]\u001b[A\n",
            " 62% 64/103 [06:54<00:54,  1.39s/it]\u001b[A\n",
            " 63% 65/103 [06:55<00:58,  1.53s/it]\u001b[A\n",
            " 64% 66/103 [06:57<00:54,  1.46s/it]\u001b[A\n",
            " 65% 67/103 [06:58<00:51,  1.43s/it]\u001b[A\n",
            " 66% 68/103 [07:00<00:52,  1.50s/it]\u001b[A\n",
            " 67% 69/103 [07:01<00:52,  1.54s/it]\u001b[A\n",
            " 68% 70/103 [07:03<00:50,  1.53s/it]\u001b[A\n",
            " 69% 71/103 [07:05<00:49,  1.56s/it]\u001b[A\n",
            " 70% 72/103 [07:06<00:47,  1.53s/it]\u001b[A\n",
            " 71% 73/103 [07:07<00:44,  1.47s/it]\u001b[A\n",
            " 72% 74/103 [07:09<00:42,  1.46s/it]\u001b[A\n",
            " 73% 75/103 [07:10<00:41,  1.48s/it]\u001b[A\n",
            " 74% 76/103 [07:12<00:38,  1.44s/it]\u001b[A\n",
            " 75% 77/103 [07:13<00:39,  1.52s/it]\u001b[A\n",
            " 76% 78/103 [07:15<00:38,  1.54s/it]\u001b[A\n",
            " 77% 79/103 [07:17<00:36,  1.54s/it]\u001b[A\n",
            " 78% 80/103 [07:18<00:33,  1.46s/it]\u001b[A\n",
            " 79% 81/103 [07:20<00:34,  1.58s/it]\u001b[A\n",
            " 80% 82/103 [07:21<00:31,  1.51s/it]\u001b[A\n",
            " 81% 83/103 [07:22<00:30,  1.50s/it]\u001b[A\n",
            " 82% 84/103 [07:24<00:29,  1.57s/it]\u001b[A\n",
            " 83% 85/103 [07:26<00:27,  1.54s/it]\u001b[A\n",
            " 83% 86/103 [07:27<00:26,  1.58s/it]\u001b[A\n",
            " 84% 87/103 [07:29<00:24,  1.55s/it]\u001b[A\n",
            " 85% 88/103 [07:30<00:23,  1.55s/it]\u001b[A\n",
            " 86% 89/103 [07:32<00:20,  1.47s/it]\u001b[A\n",
            " 87% 90/103 [07:33<00:18,  1.45s/it]\u001b[A\n",
            " 88% 91/103 [07:35<00:17,  1.48s/it]\u001b[A\n",
            " 89% 92/103 [07:36<00:16,  1.50s/it]\u001b[A\n",
            " 90% 93/103 [07:38<00:15,  1.51s/it]\u001b[A\n",
            " 91% 94/103 [07:39<00:12,  1.43s/it]\u001b[A\n",
            " 92% 95/103 [07:41<00:12,  1.56s/it]\u001b[A\n",
            " 93% 96/103 [07:42<00:10,  1.57s/it]\u001b[A\n",
            " 94% 97/103 [07:44<00:09,  1.56s/it]\u001b[A\n",
            " 95% 98/103 [07:45<00:07,  1.55s/it]\u001b[A\n",
            " 96% 99/103 [07:47<00:05,  1.44s/it]\u001b[A\n",
            " 97% 100/103 [07:49<00:04,  1.60s/it]\u001b[A\n",
            " 98% 101/103 [07:50<00:03,  1.61s/it]\u001b[A\n",
            " 99% 102/103 [07:52<00:01,  1.61s/it]\u001b[A\n",
            "100% 103/103 [07:52<00:00,  1.31s/it]\u001b[A\n",
            "Epoch:8    | validation_loss:0.1013\n",
            "\n",
            "rouge1:0.4332| rouge2:0.2068| rougeL:0.3632| rougeLsum:0.3632\n",
            "\n",
            "=============================End Validation for fine tune Epoch: 8==================================\n",
            "\n",
            "==============================saving model for fine tune: 9==================================\n",
            "\n",
            "\n",
            "100% 103/103 [08:01<00:00,  4.67s/it]\n",
            "\n",
            "Epoch:9    | Batch:0    | Gtrain_loss:0.0858| Dtrain_loss:0.0235|1.7446\n",
            "\n",
            " discrimnator prediction: 82.64%| 85.03%\n",
            " 92% 848/920 [1:44:24<04:23,  3.66s/it]\n",
            "Epoch:9    | Batch:20   | Gtrain_loss:0.1097| Dtrain_loss:0.1727|0.3346\n",
            "\n",
            " discrimnator prediction: 81.97%| 76.88%\n",
            " 94% 868/920 [1:45:35<03:01,  3.49s/it]\n",
            "Epoch:9    | Batch:40   | Gtrain_loss:0.0838| Dtrain_loss:0.3826|0.0910\n",
            "\n",
            " discrimnator prediction: 82.94%| 81.22%\n",
            " 97% 888/920 [1:46:45<01:47,  3.37s/it]\n",
            "Epoch:9    | Batch:60   | Gtrain_loss:0.0896| Dtrain_loss:0.0889|0.3158\n",
            "\n",
            " discrimnator prediction: 88.51%| 79.73%\n",
            " 99% 908/920 [1:47:51<00:39,  3.33s/it]\n",
            "Epoch:9    | Batch:80   | Gtrain_loss:0.1065| Dtrain_loss:0.1896|0.1062\n",
            "\n",
            " discrimnator prediction: 87.29%| 77.29%\n",
            "100% 920/920 [1:48:34<00:00,  3.66s/it]\n",
            "============================Start Validation for fine tune Epoch: 9================================\n",
            "\n",
            "\n",
            "  1% 1/103 [05:19<9:03:17, 319.59s/it]\u001b[A\u001b[A\n",
            "\n",
            "  2% 2/103 [05:21<3:43:00, 132.48s/it]\u001b[A\u001b[A\n",
            "\n",
            "  3% 3/103 [05:22<2:01:00, 72.60s/it] \u001b[A\u001b[A\n",
            "\n",
            "  4% 4/103 [05:24<1:13:38, 44.63s/it]\u001b[A\u001b[A\n",
            "\n",
            "  5% 5/103 [05:25<47:25, 29.03s/it]  \u001b[A\u001b[A\n",
            "\n",
            "  6% 6/103 [05:27<31:54, 19.74s/it]\u001b[A\u001b[A\n",
            "\n",
            "  7% 7/103 [05:28<22:01, 13.77s/it]\u001b[A\u001b[A\n",
            "\n",
            "  8% 8/103 [05:30<15:42,  9.92s/it]\u001b[A\u001b[A\n",
            "\n",
            "  9% 9/103 [05:31<11:21,  7.25s/it]\u001b[A\u001b[A\n",
            "\n",
            " 10% 10/103 [05:33<08:44,  5.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 11% 11/103 [05:35<06:39,  4.34s/it]\u001b[A\u001b[A\n",
            "\n",
            " 12% 12/103 [05:36<05:10,  3.42s/it]\u001b[A\u001b[A\n",
            "\n",
            " 13% 13/103 [05:37<04:12,  2.81s/it]\u001b[A\u001b[A\n",
            "\n",
            " 14% 14/103 [05:39<03:43,  2.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 15% 15/103 [05:41<03:20,  2.28s/it]\u001b[A\u001b[A\n",
            "\n",
            " 16% 16/103 [05:43<02:57,  2.04s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17% 17/103 [05:44<02:38,  1.84s/it]\u001b[A\u001b[A\n",
            "\n",
            " 17% 18/103 [05:46<02:31,  1.78s/it]\u001b[A\u001b[A\n",
            "\n",
            " 18% 19/103 [05:47<02:26,  1.74s/it]\u001b[A\u001b[A\n",
            "\n",
            " 19% 20/103 [05:49<02:19,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 20% 21/103 [05:50<02:10,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 21% 22/103 [05:52<02:10,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 22% 23/103 [05:53<02:05,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 23% 24/103 [05:55<02:07,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 24% 25/103 [05:56<01:58,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 25% 26/103 [05:58<02:04,  1.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 26% 27/103 [06:00<02:03,  1.62s/it]\u001b[A\u001b[A\n",
            "\n",
            " 27% 28/103 [06:02<02:13,  1.78s/it]\u001b[A\u001b[A\n",
            "\n",
            " 28% 29/103 [06:03<02:03,  1.67s/it]\u001b[A\u001b[A\n",
            "\n",
            " 29% 30/103 [06:05<02:01,  1.66s/it]\u001b[A\u001b[A\n",
            "\n",
            " 30% 31/103 [06:07<02:05,  1.74s/it]\u001b[A\u001b[A\n",
            "\n",
            " 31% 32/103 [06:08<01:59,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 32% 33/103 [06:10<01:56,  1.67s/it]\u001b[A\u001b[A\n",
            "\n",
            " 33% 34/103 [06:12<02:06,  1.83s/it]\u001b[A\u001b[A\n",
            "\n",
            " 34% 35/103 [06:14<01:58,  1.74s/it]\u001b[A\u001b[A\n",
            "\n",
            " 35% 36/103 [06:15<01:55,  1.73s/it]\u001b[A\u001b[A\n",
            "\n",
            " 36% 37/103 [06:17<01:53,  1.72s/it]\u001b[A\u001b[A\n",
            "\n",
            " 37% 38/103 [06:19<01:46,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 38% 39/103 [06:20<01:48,  1.70s/it]\u001b[A\u001b[A\n",
            "\n",
            " 39% 40/103 [06:22<01:45,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 40% 41/103 [06:24<01:43,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 41% 42/103 [06:25<01:39,  1.63s/it]\u001b[A\u001b[A\n",
            "\n",
            " 42% 43/103 [06:27<01:39,  1.66s/it]\u001b[A\u001b[A\n",
            "\n",
            " 43% 44/103 [06:28<01:32,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 44% 45/103 [06:30<01:33,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 45% 46/103 [06:31<01:27,  1.53s/it]\u001b[A\u001b[A\n",
            "\n",
            " 46% 47/103 [06:33<01:25,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 47% 48/103 [06:35<01:27,  1.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 48% 49/103 [06:36<01:26,  1.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 49% 50/103 [06:38<01:21,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50% 51/103 [06:40<01:29,  1.71s/it]\u001b[A\u001b[A\n",
            "\n",
            " 50% 52/103 [06:41<01:21,  1.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 51% 53/103 [06:43<01:23,  1.67s/it]\u001b[A\u001b[A\n",
            "\n",
            " 52% 54/103 [06:44<01:18,  1.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 53% 55/103 [06:46<01:12,  1.52s/it]\u001b[A\u001b[A\n",
            "\n",
            " 54% 56/103 [06:47<01:14,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 55% 57/103 [06:49<01:17,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 56% 58/103 [06:51<01:12,  1.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 57% 59/103 [06:53<01:12,  1.65s/it]\u001b[A\u001b[A\n",
            "\n",
            " 58% 60/103 [06:54<01:09,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 59% 61/103 [06:56<01:06,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 60% 62/103 [06:57<01:03,  1.54s/it]\u001b[A\u001b[A\n",
            "\n",
            " 61% 63/103 [06:58<01:00,  1.51s/it]\u001b[A\u001b[A\n",
            "\n",
            " 62% 64/103 [07:00<00:58,  1.50s/it]\u001b[A\u001b[A\n",
            "\n",
            " 63% 65/103 [07:02<01:07,  1.77s/it]\u001b[A\u001b[A\n",
            "\n",
            " 64% 66/103 [07:04<01:00,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 65% 67/103 [07:05<00:57,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 66% 68/103 [07:07<00:55,  1.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 67% 69/103 [07:08<00:54,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 68% 70/103 [07:10<00:51,  1.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 69% 71/103 [07:11<00:50,  1.58s/it]\u001b[A\u001b[A\n",
            "\n",
            " 70% 72/103 [07:13<00:50,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 71% 73/103 [07:15<00:47,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 72% 74/103 [07:16<00:47,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 73% 75/103 [07:18<00:45,  1.63s/it]\u001b[A\u001b[A\n",
            "\n",
            " 74% 76/103 [07:20<00:42,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 75% 77/103 [07:21<00:40,  1.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 76% 78/103 [07:23<00:44,  1.76s/it]\u001b[A\u001b[A\n",
            "\n",
            " 77% 79/103 [07:25<00:42,  1.76s/it]\u001b[A\u001b[A\n",
            "\n",
            " 78% 80/103 [07:26<00:36,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 79% 81/103 [07:28<00:39,  1.77s/it]\u001b[A\u001b[A\n",
            "\n",
            " 80% 82/103 [07:30<00:34,  1.66s/it]\u001b[A\u001b[A\n",
            "\n",
            " 81% 83/103 [07:32<00:33,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 82% 84/103 [07:33<00:32,  1.73s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83% 85/103 [07:35<00:30,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 83% 86/103 [07:37<00:28,  1.68s/it]\u001b[A\u001b[A\n",
            "\n",
            " 84% 87/103 [07:38<00:25,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 85% 88/103 [07:40<00:24,  1.64s/it]\u001b[A\u001b[A\n",
            "\n",
            " 86% 89/103 [07:41<00:22,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 87% 90/103 [07:43<00:20,  1.59s/it]\u001b[A\u001b[A\n",
            "\n",
            " 88% 91/103 [07:45<00:19,  1.60s/it]\u001b[A\u001b[A\n",
            "\n",
            " 89% 92/103 [07:46<00:18,  1.67s/it]\u001b[A\u001b[A\n",
            "\n",
            " 90% 93/103 [07:48<00:16,  1.65s/it]\u001b[A\u001b[A\n",
            "\n",
            " 91% 94/103 [07:49<00:14,  1.61s/it]\u001b[A\u001b[A\n",
            "\n",
            " 92% 95/103 [07:51<00:13,  1.69s/it]\u001b[A\u001b[A\n",
            "\n",
            " 93% 96/103 [07:53<00:11,  1.65s/it]\u001b[A\u001b[A\n",
            "\n",
            " 94% 97/103 [07:54<00:09,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 95% 98/103 [07:56<00:07,  1.55s/it]\u001b[A\u001b[A\n",
            "\n",
            " 96% 99/103 [07:57<00:05,  1.48s/it]\u001b[A\u001b[A\n",
            "\n",
            " 97% 100/103 [07:59<00:04,  1.57s/it]\u001b[A\u001b[A\n",
            "\n",
            " 98% 101/103 [08:00<00:03,  1.56s/it]\u001b[A\u001b[A\n",
            "\n",
            " 99% 102/103 [08:02<00:01,  1.65s/it]\u001b[A\u001b[A\n",
            "\n",
            "100% 103/103 [08:03<00:00,  1.34s/it]\u001b[A\u001b[A\n",
            "Epoch:9    | validation_loss:0.1013\n",
            "\n",
            "rouge1:0.4380| rouge2:0.2053| rougeL:0.3629| rougeLsum:0.3627\n",
            "\n",
            "=============================End Validation for fine tune Epoch: 9==================================\n",
            "\n",
            "==============================saving model for fine tune: 10==================================\n",
            "\n",
            "=============================================end fine tuning==================================\n",
            "100% 920/920 [1:51:30<00:00,  7.27s/it]\n",
            "100% 103/103 [08:13<00:00,  4.79s/it]\n",
            "  0% 0/467 [00:00<?, ?it/s]\n",
            "=============================================generate pseudo label==================================\n",
            "100% 467/467 [38:22<00:00,  3.88s/it]\n",
            "========================================end generate pseudo label==================================\n",
            "number of labels generated:  1724\n",
            "100% 467/467 [38:22<00:00,  4.93s/it]\n",
            "\n",
            "=============================================start training==================================\n",
            "\n",
            "Num_Epochs:0, Batch_size:8\n",
            "  0% 0/200 [00:00<?, ?it/s]\n",
            "  0% 0/103 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch:0    | Batch:0    | Gtrain_loss:1.0982| Dtrain_loss:0.2820|1.1652\n",
            "\n",
            " discrimnator prediction: 94.38%| 48.49%\n",
            " 10% 20/200 [00:56<07:18,  2.44s/it]\n",
            "Epoch:0    | Batch:20   | Gtrain_loss:0.4953| Dtrain_loss:0.3294|0.5906\n",
            "\n",
            " discrimnator prediction: 76.99%| 76.04%\n",
            " 20% 40/200 [01:48<07:06,  2.67s/it]\n",
            "Epoch:0    | Batch:40   | Gtrain_loss:0.4683| Dtrain_loss:0.0840|0.6985\n",
            "\n",
            " discrimnator prediction: 88.30%| 71.99%\n",
            " 30% 60/200 [02:44<06:10,  2.65s/it]\n",
            "Epoch:0    | Batch:60   | Gtrain_loss:0.4496| Dtrain_loss:0.1937|0.0230\n",
            "\n",
            " discrimnator prediction: 90.82%| 84.97%\n",
            " 40% 80/200 [03:38<05:34,  2.79s/it]\n",
            "Epoch:0    | Batch:80   | Gtrain_loss:0.3283| Dtrain_loss:0.4576|0.0317\n",
            "\n",
            " discrimnator prediction: 84.54%| 82.35%\n",
            " 50% 100/200 [04:30<04:18,  2.59s/it]\n",
            "Epoch:0    | Batch:100  | Gtrain_loss:0.5449| Dtrain_loss:0.0470|0.0421\n",
            "\n",
            " discrimnator prediction: 84.58%| 84.87%\n",
            " 60% 120/200 [05:24<03:33,  2.67s/it]\n",
            "Epoch:0    | Batch:120  | Gtrain_loss:0.5652| Dtrain_loss:0.2452|0.0290\n",
            "\n",
            " discrimnator prediction: 82.72%| 84.23%\n",
            " 70% 140/200 [06:16<02:37,  2.62s/it]\n",
            "Epoch:0    | Batch:140  | Gtrain_loss:0.3664| Dtrain_loss:0.7879|0.0173\n",
            "\n",
            " discrimnator prediction: 89.97%| 88.65%\n",
            " 80% 160/200 [07:08<01:43,  2.58s/it]\n",
            "Epoch:0    | Batch:160  | Gtrain_loss:0.5642| Dtrain_loss:0.0271|0.0493\n",
            "\n",
            " discrimnator prediction: 85.98%| 87.23%\n",
            " 90% 180/200 [08:07<00:50,  2.54s/it]\n",
            "Epoch:0    | Batch:180  | Gtrain_loss:0.4187| Dtrain_loss:0.1830|0.4710\n",
            "\n",
            " discrimnator prediction: 77.85%| 78.19%\n",
            " 92% 184/200 [08:17<00:38,  2.44s/it]\n",
            "======================================Start Validation for Epoch: 0==================================\n",
            "\n",
            "  1% 1/103 [08:19<14:08:20, 499.02s/it]\u001b[A\n",
            "  2% 2/103 [08:20<5:47:09, 206.23s/it] \u001b[A\n",
            "  3% 3/103 [08:21<3:07:45, 112.65s/it]\u001b[A\n",
            "  4% 4/103 [08:23<1:53:31, 68.81s/it] \u001b[A\n",
            "  5% 5/103 [08:24<1:12:35, 44.44s/it]\u001b[A\n",
            "  6% 6/103 [08:26<48:17, 29.87s/it]  \u001b[A\n",
            "  7% 7/103 [08:27<32:53, 20.56s/it]\u001b[A\n",
            "  8% 8/103 [08:29<23:02, 14.56s/it]\u001b[A\n",
            "  9% 9/103 [08:30<16:20, 10.44s/it]\u001b[A\n",
            " 10% 10/103 [08:31<11:52,  7.66s/it]\u001b[A\n",
            " 11% 11/103 [08:33<08:52,  5.78s/it]\u001b[A\n",
            " 12% 12/103 [08:34<06:41,  4.41s/it]\u001b[A\n",
            " 13% 13/103 [08:36<05:13,  3.49s/it]\u001b[A\n",
            " 14% 14/103 [08:37<04:08,  2.79s/it]\u001b[A\n",
            " 15% 15/103 [08:38<03:32,  2.41s/it]\u001b[A\n",
            " 16% 16/103 [08:40<03:02,  2.09s/it]\u001b[A\n",
            " 17% 17/103 [08:41<02:40,  1.86s/it]\u001b[A\n",
            " 17% 18/103 [08:42<02:25,  1.72s/it]\u001b[A\n",
            " 18% 19/103 [08:44<02:15,  1.62s/it]\u001b[A\n",
            " 19% 20/103 [08:45<02:09,  1.56s/it]\u001b[A\n",
            " 20% 21/103 [08:46<01:58,  1.44s/it]\u001b[A\n",
            " 21% 22/103 [08:48<01:55,  1.43s/it]\u001b[A\n",
            " 22% 23/103 [08:49<01:58,  1.48s/it]\u001b[A\n",
            " 23% 24/103 [08:51<01:56,  1.47s/it]\u001b[A\n",
            " 24% 25/103 [08:52<01:49,  1.40s/it]\u001b[A\n",
            " 25% 26/103 [08:53<01:46,  1.38s/it]\u001b[A\n",
            " 26% 27/103 [08:55<01:45,  1.39s/it]\u001b[A\n",
            " 27% 28/103 [08:56<01:48,  1.45s/it]\u001b[A\n",
            " 28% 29/103 [08:58<01:43,  1.40s/it]\u001b[A\n",
            " 29% 30/103 [08:59<01:43,  1.42s/it]\u001b[A\n",
            " 30% 31/103 [09:01<01:43,  1.43s/it]\u001b[A\n",
            " 31% 32/103 [09:02<01:46,  1.50s/it]\u001b[A\n",
            " 32% 33/103 [09:04<01:43,  1.48s/it]\u001b[A\n",
            " 33% 34/103 [09:05<01:45,  1.53s/it]\u001b[A\n",
            " 34% 35/103 [09:07<01:43,  1.52s/it]\u001b[A\n",
            " 35% 36/103 [09:08<01:41,  1.52s/it]\u001b[A\n",
            " 36% 37/103 [09:10<01:44,  1.59s/it]\u001b[A\n",
            " 37% 38/103 [09:11<01:39,  1.52s/it]\u001b[A\n",
            " 38% 39/103 [09:13<01:37,  1.52s/it]\u001b[A\n",
            " 39% 40/103 [09:15<01:37,  1.54s/it]\u001b[A\n",
            " 40% 41/103 [09:16<01:31,  1.48s/it]\u001b[A\n",
            " 41% 42/103 [09:17<01:27,  1.44s/it]\u001b[A\n",
            " 42% 43/103 [09:19<01:36,  1.61s/it]\u001b[A\n",
            " 43% 44/103 [09:21<01:29,  1.51s/it]\u001b[A\n",
            " 44% 45/103 [09:22<01:29,  1.54s/it]\u001b[A\n",
            " 45% 46/103 [09:24<01:28,  1.56s/it]\u001b[A\n",
            " 46% 47/103 [09:25<01:23,  1.49s/it]\u001b[A\n",
            " 47% 48/103 [09:27<01:25,  1.55s/it]\u001b[A\n",
            " 48% 49/103 [09:28<01:21,  1.51s/it]\u001b[A\n",
            " 49% 50/103 [09:30<01:17,  1.47s/it]\u001b[A\n",
            " 50% 51/103 [09:31<01:19,  1.53s/it]\u001b[A\n",
            " 50% 52/103 [09:32<01:13,  1.45s/it]\u001b[A\n",
            " 51% 53/103 [09:34<01:11,  1.43s/it]\u001b[A\n",
            " 52% 54/103 [09:35<01:08,  1.41s/it]\u001b[A\n",
            " 53% 55/103 [09:37<01:06,  1.38s/it]\u001b[A\n",
            " 54% 56/103 [09:38<01:03,  1.35s/it]\u001b[A\n",
            " 55% 57/103 [09:39<01:02,  1.37s/it]\u001b[A\n",
            " 56% 58/103 [09:41<01:01,  1.37s/it]\u001b[A\n",
            " 57% 59/103 [09:42<01:04,  1.46s/it]\u001b[A\n",
            " 58% 60/103 [09:44<01:00,  1.41s/it]\u001b[A\n",
            " 59% 61/103 [09:45<00:57,  1.37s/it]\u001b[A\n",
            " 60% 62/103 [09:46<00:56,  1.37s/it]\u001b[A\n",
            " 61% 63/103 [09:48<00:54,  1.35s/it]\u001b[A\n",
            " 62% 64/103 [09:49<00:50,  1.31s/it]\u001b[A\n",
            " 63% 65/103 [09:50<00:53,  1.42s/it]\u001b[A\n",
            " 64% 66/103 [09:52<00:51,  1.39s/it]\u001b[A\n",
            " 65% 67/103 [09:53<00:49,  1.38s/it]\u001b[A\n",
            " 66% 68/103 [09:55<00:48,  1.40s/it]\u001b[A\n",
            " 67% 69/103 [09:56<00:45,  1.35s/it]\u001b[A\n",
            " 68% 70/103 [09:57<00:46,  1.40s/it]\u001b[A\n",
            " 69% 71/103 [09:59<00:44,  1.41s/it]\u001b[A\n",
            " 70% 72/103 [10:00<00:43,  1.40s/it]\u001b[A\n",
            " 71% 73/103 [10:02<00:42,  1.42s/it]\u001b[A\n",
            " 72% 74/103 [10:03<00:40,  1.41s/it]\u001b[A\n",
            " 73% 75/103 [10:05<00:41,  1.49s/it]\u001b[A\n",
            " 74% 76/103 [10:06<00:38,  1.44s/it]\u001b[A\n",
            " 75% 77/103 [10:07<00:37,  1.45s/it]\u001b[A\n",
            " 76% 78/103 [10:09<00:38,  1.56s/it]\u001b[A\n",
            " 77% 79/103 [10:11<00:36,  1.52s/it]\u001b[A\n",
            " 78% 80/103 [10:12<00:32,  1.43s/it]\u001b[A\n",
            " 79% 81/103 [10:14<00:33,  1.52s/it]\u001b[A\n",
            " 80% 82/103 [10:15<00:30,  1.48s/it]\u001b[A\n",
            " 81% 83/103 [10:16<00:28,  1.45s/it]\u001b[A\n",
            " 82% 84/103 [10:18<00:28,  1.52s/it]\u001b[A\n",
            " 83% 85/103 [10:19<00:25,  1.43s/it]\u001b[A\n",
            " 83% 86/103 [10:21<00:24,  1.44s/it]\u001b[A\n",
            " 84% 87/103 [10:22<00:23,  1.45s/it]\u001b[A\n",
            " 85% 88/103 [10:23<00:21,  1.41s/it]\u001b[A\n",
            " 86% 89/103 [10:25<00:19,  1.38s/it]\u001b[A\n",
            " 87% 90/103 [10:26<00:17,  1.36s/it]\u001b[A\n",
            " 88% 91/103 [10:28<00:16,  1.41s/it]\u001b[A\n",
            " 89% 92/103 [10:29<00:16,  1.48s/it]\u001b[A\n",
            " 90% 93/103 [10:31<00:15,  1.54s/it]\u001b[A\n",
            " 91% 94/103 [10:32<00:12,  1.43s/it]\u001b[A\n",
            " 92% 95/103 [10:34<00:12,  1.51s/it]\u001b[A\n",
            " 93% 96/103 [10:35<00:10,  1.49s/it]\u001b[A\n",
            " 94% 97/103 [10:37<00:08,  1.47s/it]\u001b[A\n",
            " 95% 98/103 [10:38<00:07,  1.42s/it]\u001b[A\n",
            " 96% 99/103 [10:39<00:05,  1.34s/it]\u001b[A\n",
            " 97% 100/103 [10:41<00:04,  1.45s/it]\u001b[A\n",
            " 98% 101/103 [10:42<00:02,  1.41s/it]\u001b[A\n",
            " 99% 102/103 [10:44<00:01,  1.47s/it]\u001b[A\n",
            "100% 103/103 [10:44<00:00,  1.23s/it]\u001b[A\n",
            "Epoch:0    | validation_loss:0.1025\n",
            "\n",
            "rouge1:0.4209| rouge2:0.1991| rougeL:0.3569| rougeLsum:0.3569\n",
            "\n",
            "======================================End Validation for Epoch: 0==================================\n",
            "\n",
            "======================================saving model for : 0==================================\n",
            "\n",
            "=============================================end training==================================\n",
            " 92% 184/200 [10:53<00:56,  3.55s/it]\n",
            "100% 103/103 [10:53<00:00,  6.34s/it]\n",
            "  0% 0/467 [00:00<?, ?it/s]\n",
            "=============================================generate pseudo label==================================\n",
            "100% 467/467 [32:33<00:00,  3.41s/it]\n",
            "========================================end generate pseudo label==================================\n",
            "number of labels generated:  2394\n",
            "100% 467/467 [32:33<00:00,  4.18s/it]\n",
            "\n",
            "=============================================start training==================================\n",
            "\n",
            "Num_Epochs:1, Batch_size:8\n",
            "  0% 0/200 [00:00<?, ?it/s]\n",
            "  0% 0/103 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch:1    | Batch:0    | Gtrain_loss:0.3960| Dtrain_loss:0.1409|0.8579\n",
            "\n",
            " discrimnator prediction: 94.38%| 70.07%\n",
            " 10% 20/200 [00:54<07:49,  2.61s/it]\n",
            "Epoch:1    | Batch:20   | Gtrain_loss:0.4155| Dtrain_loss:0.0206|0.1324\n",
            "\n",
            " discrimnator prediction: 84.01%| 84.39%\n",
            " 20% 40/200 [01:54<07:31,  2.82s/it]\n",
            "Epoch:1    | Batch:40   | Gtrain_loss:0.2667| Dtrain_loss:0.2868|0.3774\n",
            "\n",
            " discrimnator prediction: 81.27%| 76.64%\n",
            " 30% 60/200 [02:48<06:20,  2.72s/it]\n",
            "Epoch:1    | Batch:60   | Gtrain_loss:0.3597| Dtrain_loss:0.4184|0.0141\n",
            "\n",
            " discrimnator prediction: 89.54%| 83.79%\n",
            " 40% 80/200 [03:41<05:27,  2.73s/it]\n",
            "Epoch:1    | Batch:80   | Gtrain_loss:0.2647| Dtrain_loss:0.2979|0.1088\n",
            "\n",
            " discrimnator prediction: 87.90%| 84.63%\n",
            " 50% 100/200 [04:35<04:16,  2.57s/it]\n",
            "Epoch:1    | Batch:100  | Gtrain_loss:0.4235| Dtrain_loss:0.0962|0.0224\n",
            "\n",
            " discrimnator prediction: 83.54%| 78.93%\n",
            " 60% 120/200 [05:28<03:26,  2.58s/it]\n",
            "Epoch:1    | Batch:120  | Gtrain_loss:0.3480| Dtrain_loss:0.1722|0.0925\n",
            "\n",
            " discrimnator prediction: 80.37%| 81.90%\n",
            " 70% 140/200 [06:20<02:30,  2.50s/it]\n",
            "Epoch:1    | Batch:140  | Gtrain_loss:0.3546| Dtrain_loss:0.0395|0.2544\n",
            "\n",
            " discrimnator prediction: 88.68%| 84.15%\n",
            " 80% 160/200 [07:14<01:42,  2.55s/it]\n",
            "Epoch:1    | Batch:160  | Gtrain_loss:0.3496| Dtrain_loss:0.3729|0.2350\n",
            "\n",
            " discrimnator prediction: 80.09%| 74.32%\n",
            " 90% 180/200 [08:08<00:52,  2.60s/it]\n",
            "Epoch:1    | Batch:180  | Gtrain_loss:0.2381| Dtrain_loss:1.1710|0.4915\n",
            "\n",
            " discrimnator prediction: 79.31%| 82.85%\n",
            " 92% 184/200 [08:18<00:40,  2.52s/it]\n",
            "======================================Start Validation for Epoch: 1==================================\n",
            "\n",
            "  1% 1/103 [08:20<14:10:58, 500.57s/it]\u001b[A\n",
            "  2% 2/103 [08:22<5:48:22, 206.96s/it] \u001b[A\n",
            "  3% 3/103 [08:23<3:08:24, 113.05s/it]\u001b[A\n",
            "  4% 4/103 [08:24<1:53:51, 69.01s/it] \u001b[A\n",
            "  5% 5/103 [08:26<1:12:49, 44.59s/it]\u001b[A\n",
            "  6% 6/103 [08:27<48:24, 29.95s/it]  \u001b[A\n",
            "  7% 7/103 [08:29<33:00, 20.63s/it]\u001b[A\n",
            "  8% 8/103 [08:31<23:15, 14.69s/it]\u001b[A\n",
            "  9% 9/103 [08:32<16:30, 10.54s/it]\u001b[A\n",
            " 10% 10/103 [08:33<12:00,  7.75s/it]\u001b[A\n",
            " 11% 11/103 [08:35<08:51,  5.77s/it]\u001b[A\n",
            " 12% 12/103 [08:36<06:43,  4.43s/it]\u001b[A\n",
            " 13% 13/103 [08:38<05:19,  3.55s/it]\u001b[A\n",
            " 14% 14/103 [08:39<04:15,  2.87s/it]\u001b[A\n",
            " 15% 15/103 [08:40<03:36,  2.47s/it]\u001b[A\n",
            " 16% 16/103 [08:42<03:05,  2.14s/it]\u001b[A\n",
            " 17% 17/103 [08:43<02:43,  1.90s/it]\u001b[A\n",
            " 17% 18/103 [08:45<02:28,  1.75s/it]\u001b[A\n",
            " 18% 19/103 [08:46<02:20,  1.68s/it]\u001b[A\n",
            " 19% 20/103 [08:48<02:16,  1.64s/it]\u001b[A\n",
            " 20% 21/103 [08:49<02:05,  1.53s/it]\u001b[A\n",
            " 21% 22/103 [08:50<02:04,  1.54s/it]\u001b[A\n",
            " 22% 23/103 [08:52<02:02,  1.53s/it]\u001b[A\n",
            " 23% 24/103 [08:54<02:02,  1.55s/it]\u001b[A\n",
            " 24% 25/103 [08:55<01:53,  1.46s/it]\u001b[A\n",
            " 25% 26/103 [08:56<01:50,  1.43s/it]\u001b[A\n",
            " 26% 27/103 [08:58<01:49,  1.44s/it]\u001b[A\n",
            " 27% 28/103 [08:59<01:52,  1.50s/it]\u001b[A\n",
            " 28% 29/103 [09:01<01:49,  1.48s/it]\u001b[A\n",
            " 29% 30/103 [09:02<01:46,  1.46s/it]\u001b[A\n",
            " 30% 31/103 [09:04<01:48,  1.51s/it]\u001b[A\n",
            " 31% 32/103 [09:05<01:48,  1.53s/it]\u001b[A\n",
            " 32% 33/103 [09:07<01:45,  1.51s/it]\u001b[A\n",
            " 33% 34/103 [09:08<01:45,  1.53s/it]\u001b[A\n",
            " 34% 35/103 [09:10<01:40,  1.48s/it]\u001b[A\n",
            " 35% 36/103 [09:11<01:38,  1.48s/it]\u001b[A\n",
            " 36% 37/103 [09:13<01:38,  1.49s/it]\u001b[A\n",
            " 37% 38/103 [09:14<01:31,  1.41s/it]\u001b[A\n",
            " 38% 39/103 [09:15<01:32,  1.44s/it]\u001b[A\n",
            " 39% 40/103 [09:17<01:34,  1.51s/it]\u001b[A\n",
            " 40% 41/103 [09:19<01:31,  1.48s/it]\u001b[A\n",
            " 41% 42/103 [09:20<01:28,  1.45s/it]\u001b[A\n",
            " 42% 43/103 [09:21<01:28,  1.48s/it]\u001b[A\n",
            " 43% 44/103 [09:23<01:20,  1.37s/it]\u001b[A\n",
            " 44% 45/103 [09:24<01:18,  1.36s/it]\u001b[A\n",
            " 45% 46/103 [09:26<01:22,  1.44s/it]\u001b[A\n",
            " 46% 47/103 [09:27<01:17,  1.38s/it]\u001b[A\n",
            " 47% 48/103 [09:29<01:22,  1.50s/it]\u001b[A\n",
            " 48% 49/103 [09:30<01:19,  1.47s/it]\u001b[A\n",
            " 49% 50/103 [09:31<01:13,  1.39s/it]\u001b[A\n",
            " 50% 51/103 [09:33<01:20,  1.55s/it]\u001b[A\n",
            " 50% 52/103 [09:34<01:15,  1.48s/it]\u001b[A\n",
            " 51% 53/103 [09:36<01:13,  1.46s/it]\u001b[A\n",
            " 52% 54/103 [09:37<01:10,  1.45s/it]\u001b[A\n",
            " 53% 55/103 [09:39<01:08,  1.43s/it]\u001b[A\n",
            " 54% 56/103 [09:40<01:08,  1.47s/it]\u001b[A\n",
            " 55% 57/103 [09:42<01:08,  1.49s/it]\u001b[A\n",
            " 56% 58/103 [09:43<01:07,  1.50s/it]\u001b[A\n",
            " 57% 59/103 [09:45<01:06,  1.52s/it]\u001b[A\n",
            " 58% 60/103 [09:46<01:06,  1.54s/it]\u001b[A\n",
            " 59% 61/103 [09:48<01:03,  1.50s/it]\u001b[A\n",
            " 60% 62/103 [09:49<01:00,  1.49s/it]\u001b[A\n",
            " 61% 63/103 [09:50<00:55,  1.39s/it]\u001b[A\n",
            " 62% 64/103 [09:52<00:53,  1.37s/it]\u001b[A\n",
            " 63% 65/103 [09:53<00:55,  1.46s/it]\u001b[A\n",
            " 64% 66/103 [09:55<00:53,  1.44s/it]\u001b[A\n",
            " 65% 67/103 [09:56<00:50,  1.40s/it]\u001b[A\n",
            " 66% 68/103 [09:58<00:49,  1.41s/it]\u001b[A\n",
            " 67% 69/103 [09:59<00:48,  1.44s/it]\u001b[A\n",
            " 68% 70/103 [10:01<00:47,  1.45s/it]\u001b[A\n",
            " 69% 71/103 [10:02<00:46,  1.45s/it]\u001b[A\n",
            " 70% 72/103 [10:03<00:43,  1.41s/it]\u001b[A\n",
            " 71% 73/103 [10:05<00:41,  1.37s/it]\u001b[A\n",
            " 72% 74/103 [10:06<00:40,  1.39s/it]\u001b[A\n",
            " 73% 75/103 [10:07<00:38,  1.38s/it]\u001b[A\n",
            " 74% 76/103 [10:09<00:37,  1.38s/it]\u001b[A\n",
            " 75% 77/103 [10:10<00:36,  1.40s/it]\u001b[A\n",
            " 76% 78/103 [10:12<00:36,  1.45s/it]\u001b[A\n",
            " 77% 79/103 [10:13<00:35,  1.47s/it]\u001b[A\n",
            " 78% 80/103 [10:15<00:33,  1.44s/it]\u001b[A\n",
            " 79% 81/103 [10:16<00:31,  1.42s/it]\u001b[A\n",
            " 80% 82/103 [10:17<00:29,  1.38s/it]\u001b[A\n",
            " 81% 83/103 [10:19<00:27,  1.40s/it]\u001b[A\n",
            " 82% 84/103 [10:21<00:29,  1.58s/it]\u001b[A\n",
            " 83% 85/103 [10:22<00:27,  1.51s/it]\u001b[A\n",
            " 83% 86/103 [10:24<00:25,  1.50s/it]\u001b[A\n",
            " 84% 87/103 [10:25<00:23,  1.47s/it]\u001b[A\n",
            " 85% 88/103 [10:27<00:22,  1.51s/it]\u001b[A\n",
            " 86% 89/103 [10:28<00:20,  1.48s/it]\u001b[A\n",
            " 87% 90/103 [10:29<00:18,  1.44s/it]\u001b[A\n",
            " 88% 91/103 [10:31<00:17,  1.43s/it]\u001b[A\n",
            " 89% 92/103 [10:32<00:15,  1.43s/it]\u001b[A\n",
            " 90% 93/103 [10:34<00:15,  1.51s/it]\u001b[A\n",
            " 91% 94/103 [10:35<00:13,  1.45s/it]\u001b[A\n",
            " 92% 95/103 [10:37<00:12,  1.54s/it]\u001b[A\n",
            " 93% 96/103 [10:38<00:10,  1.53s/it]\u001b[A\n",
            " 94% 97/103 [10:40<00:09,  1.52s/it]\u001b[A\n",
            " 95% 98/103 [10:41<00:07,  1.53s/it]\u001b[A\n",
            " 96% 99/103 [10:43<00:06,  1.54s/it]\u001b[A\n",
            " 97% 100/103 [10:45<00:04,  1.54s/it]\u001b[A\n",
            " 98% 101/103 [10:46<00:03,  1.53s/it]\u001b[A\n",
            " 99% 102/103 [10:48<00:01,  1.60s/it]\u001b[A\n",
            "100% 103/103 [10:49<00:00,  1.33s/it]\u001b[A\n",
            "Epoch:1    | validation_loss:0.1036\n",
            "\n",
            "rouge1:0.4310| rouge2:0.2074| rougeL:0.3620| rougeLsum:0.3617\n",
            "\n",
            "======================================End Validation for Epoch: 1==================================\n",
            "\n",
            "======================================saving model for : 1==================================\n",
            "\n",
            "=============================================end training==================================\n",
            " 92% 184/200 [10:57<00:57,  3.57s/it]\n",
            "100% 103/103 [10:57<00:00,  6.38s/it]\n",
            "  0% 0/467 [00:00<?, ?it/s]\n",
            "=============================================generate pseudo label==================================\n",
            "100% 467/467 [32:56<00:00,  3.55s/it]\n",
            "========================================end generate pseudo label==================================\n",
            "number of labels generated:  1155\n",
            "100% 467/467 [32:56<00:00,  4.23s/it]\n",
            "\n",
            "=============================================start training==================================\n",
            "\n",
            "Num_Epochs:2, Batch_size:8\n",
            "  0% 0/200 [00:00<?, ?it/s]\n",
            "  0% 0/103 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch:2    | Batch:0    | Gtrain_loss:0.3012| Dtrain_loss:0.9990|0.2855\n",
            "\n",
            " discrimnator prediction: 48.97%| 70.07%\n",
            " 10% 20/200 [00:51<07:25,  2.47s/it]\n",
            "Epoch:2    | Batch:20   | Gtrain_loss:0.2677| Dtrain_loss:0.3156|0.0665\n",
            "\n",
            " discrimnator prediction: 76.91%| 68.85%\n",
            " 20% 40/200 [01:47<08:12,  3.08s/it]\n",
            "Epoch:2    | Batch:40   | Gtrain_loss:0.3023| Dtrain_loss:0.3698|0.5791\n",
            "\n",
            " discrimnator prediction: 89.55%| 67.43%\n",
            " 30% 60/200 [02:42<06:21,  2.72s/it]\n",
            "Epoch:2    | Batch:60   | Gtrain_loss:0.3376| Dtrain_loss:0.1192|1.3673\n",
            "\n",
            " discrimnator prediction: 84.82%| 87.26%\n",
            " 40% 80/200 [03:38<05:49,  2.91s/it]\n",
            "Epoch:2    | Batch:80   | Gtrain_loss:0.2687| Dtrain_loss:0.0795|0.1633\n",
            "\n",
            " discrimnator prediction: 79.87%| 78.65%\n",
            " 50% 100/200 [04:34<04:28,  2.68s/it]\n",
            "Epoch:2    | Batch:100  | Gtrain_loss:0.3923| Dtrain_loss:0.0606|0.0793\n",
            "\n",
            " discrimnator prediction: 84.80%| 76.65%\n",
            " 60% 120/200 [05:26<03:32,  2.65s/it]\n",
            "Epoch:2    | Batch:120  | Gtrain_loss:0.1840| Dtrain_loss:0.3198|0.0269\n",
            "\n",
            " discrimnator prediction: 83.99%| 78.21%\n",
            " 70% 140/200 [06:19<02:35,  2.60s/it]\n",
            "Epoch:2    | Batch:140  | Gtrain_loss:0.2071| Dtrain_loss:0.2576|0.3262\n",
            "\n",
            " discrimnator prediction: 89.83%| 75.54%\n",
            " 80% 160/200 [07:13<01:47,  2.69s/it]\n",
            "Epoch:2    | Batch:160  | Gtrain_loss:0.2214| Dtrain_loss:0.1246|0.0097\n",
            "\n",
            " discrimnator prediction: 89.56%| 83.69%\n",
            " 90% 180/200 [08:07<00:51,  2.58s/it]\n",
            "Epoch:2    | Batch:180  | Gtrain_loss:0.1723| Dtrain_loss:0.1452|0.3514\n",
            "\n",
            " discrimnator prediction: 86.31%| 80.50%\n",
            " 92% 184/200 [08:18<00:42,  2.64s/it]\n",
            "======================================Start Validation for Epoch: 2==================================\n",
            "\n",
            "  1% 1/103 [08:20<14:10:17, 500.17s/it]\u001b[A\n",
            "  2% 2/103 [08:21<5:48:27, 207.00s/it] \u001b[A\n",
            "  3% 3/103 [08:23<3:08:26, 113.06s/it]\u001b[A\n",
            "  4% 4/103 [08:24<1:53:58, 69.08s/it] \u001b[A\n",
            "  5% 5/103 [08:26<1:12:56, 44.66s/it]\u001b[A\n",
            "  6% 6/103 [08:27<48:31, 30.02s/it]  \u001b[A\n",
            "  7% 7/103 [08:29<33:02, 20.65s/it]\u001b[A\n",
            "  8% 8/103 [08:31<23:21, 14.75s/it]\u001b[A\n",
            "  9% 9/103 [08:32<16:34, 10.58s/it]\u001b[A\n",
            " 10% 10/103 [08:34<12:15,  7.91s/it]\u001b[A\n",
            " 11% 11/103 [08:36<09:02,  5.90s/it]\u001b[A\n",
            " 12% 12/103 [08:37<06:46,  4.47s/it]\u001b[A\n",
            " 13% 13/103 [08:38<05:21,  3.57s/it]\u001b[A\n",
            " 14% 14/103 [08:39<04:14,  2.86s/it]\u001b[A\n",
            " 15% 15/103 [08:41<03:40,  2.50s/it]\u001b[A\n",
            " 16% 16/103 [08:43<03:13,  2.22s/it]\u001b[A\n",
            " 17% 17/103 [08:44<02:48,  1.96s/it]\u001b[A\n",
            " 17% 18/103 [08:45<02:33,  1.81s/it]\u001b[A\n",
            " 18% 19/103 [08:47<02:24,  1.72s/it]\u001b[A\n",
            " 19% 20/103 [08:49<02:24,  1.74s/it]\u001b[A\n",
            " 20% 21/103 [08:50<02:11,  1.60s/it]\u001b[A\n",
            " 21% 22/103 [08:52<02:13,  1.65s/it]\u001b[A\n",
            " 22% 23/103 [08:53<02:08,  1.60s/it]\u001b[A\n",
            " 23% 24/103 [08:55<02:08,  1.62s/it]\u001b[A\n",
            " 24% 25/103 [08:56<01:56,  1.49s/it]\u001b[A\n",
            " 25% 26/103 [08:58<01:56,  1.51s/it]\u001b[A\n",
            " 26% 27/103 [08:59<01:55,  1.52s/it]\u001b[A\n",
            " 27% 28/103 [09:01<01:59,  1.59s/it]\u001b[A\n",
            " 28% 29/103 [09:02<01:52,  1.51s/it]\u001b[A\n",
            " 29% 30/103 [09:04<01:51,  1.52s/it]\u001b[A\n",
            " 30% 31/103 [09:06<01:57,  1.63s/it]\u001b[A\n",
            " 31% 32/103 [09:07<01:50,  1.56s/it]\u001b[A\n",
            " 32% 33/103 [09:09<01:48,  1.55s/it]\u001b[A\n",
            " 33% 34/103 [09:10<01:48,  1.58s/it]\u001b[A\n",
            " 34% 35/103 [09:12<01:42,  1.51s/it]\u001b[A\n",
            " 35% 36/103 [09:13<01:39,  1.49s/it]\u001b[A\n",
            " 36% 37/103 [09:15<01:41,  1.53s/it]\u001b[A\n",
            " 37% 38/103 [09:16<01:36,  1.48s/it]\u001b[A\n",
            " 38% 39/103 [09:18<01:37,  1.52s/it]\u001b[A\n",
            " 39% 40/103 [09:19<01:39,  1.58s/it]\u001b[A\n",
            " 40% 41/103 [09:21<01:38,  1.60s/it]\u001b[A\n",
            " 41% 42/103 [09:22<01:34,  1.54s/it]\u001b[A\n",
            " 42% 43/103 [09:24<01:34,  1.58s/it]\u001b[A\n",
            " 43% 44/103 [09:26<01:30,  1.53s/it]\u001b[A\n",
            " 44% 45/103 [09:27<01:31,  1.59s/it]\u001b[A\n",
            " 45% 46/103 [09:29<01:30,  1.59s/it]\u001b[A\n",
            " 46% 47/103 [09:31<01:30,  1.61s/it]\u001b[A\n",
            " 47% 48/103 [09:32<01:31,  1.66s/it]\u001b[A\n",
            " 48% 49/103 [09:34<01:29,  1.66s/it]\u001b[A\n",
            " 49% 50/103 [09:35<01:23,  1.57s/it]\u001b[A\n",
            " 50% 51/103 [09:37<01:30,  1.73s/it]\u001b[A\n",
            " 50% 52/103 [09:39<01:23,  1.63s/it]\u001b[A\n",
            " 51% 53/103 [09:40<01:20,  1.60s/it]\u001b[A\n",
            " 52% 54/103 [09:42<01:14,  1.52s/it]\u001b[A\n",
            " 53% 55/103 [09:43<01:09,  1.44s/it]\u001b[A\n",
            " 54% 56/103 [09:44<01:08,  1.45s/it]\u001b[A\n",
            " 55% 57/103 [09:46<01:09,  1.51s/it]\u001b[A\n",
            " 56% 58/103 [09:48<01:11,  1.59s/it]\u001b[A\n",
            " 57% 59/103 [09:49<01:09,  1.59s/it]\u001b[A\n",
            " 58% 60/103 [09:51<01:06,  1.54s/it]\u001b[A\n",
            " 59% 61/103 [09:52<01:02,  1.48s/it]\u001b[A\n",
            " 60% 62/103 [09:54<01:01,  1.51s/it]\u001b[A\n",
            " 61% 63/103 [09:55<00:59,  1.48s/it]\u001b[A\n",
            " 62% 64/103 [09:57<00:55,  1.43s/it]\u001b[A\n",
            " 63% 65/103 [09:58<00:59,  1.58s/it]\u001b[A\n",
            " 64% 66/103 [10:00<00:57,  1.56s/it]\u001b[A\n",
            " 65% 67/103 [10:01<00:53,  1.48s/it]\u001b[A\n",
            " 66% 68/103 [10:03<00:50,  1.44s/it]\u001b[A\n",
            " 67% 69/103 [10:04<00:49,  1.46s/it]\u001b[A\n",
            " 68% 70/103 [10:06<00:49,  1.51s/it]\u001b[A\n",
            " 69% 71/103 [10:07<00:48,  1.50s/it]\u001b[A\n",
            " 70% 72/103 [10:09<00:45,  1.47s/it]\u001b[A\n",
            " 71% 73/103 [10:10<00:42,  1.42s/it]\u001b[A\n",
            " 72% 74/103 [10:11<00:41,  1.43s/it]\u001b[A\n",
            " 73% 75/103 [10:13<00:40,  1.46s/it]\u001b[A\n",
            " 74% 76/103 [10:14<00:39,  1.47s/it]\u001b[A\n",
            " 75% 77/103 [10:16<00:38,  1.46s/it]\u001b[A\n",
            " 76% 78/103 [10:18<00:38,  1.52s/it]\u001b[A\n",
            " 77% 79/103 [10:19<00:37,  1.56s/it]\u001b[A\n",
            " 78% 80/103 [10:20<00:34,  1.48s/it]\u001b[A\n",
            " 79% 81/103 [10:22<00:34,  1.55s/it]\u001b[A\n",
            " 80% 82/103 [10:23<00:31,  1.48s/it]\u001b[A\n",
            " 81% 83/103 [10:25<00:29,  1.47s/it]\u001b[A\n",
            " 82% 84/103 [10:27<00:29,  1.56s/it]\u001b[A\n",
            " 83% 85/103 [10:28<00:28,  1.57s/it]\u001b[A\n",
            " 83% 86/103 [10:30<00:26,  1.58s/it]\u001b[A\n",
            " 84% 87/103 [10:31<00:24,  1.56s/it]\u001b[A\n",
            " 85% 88/103 [10:33<00:23,  1.54s/it]\u001b[A\n",
            " 86% 89/103 [10:34<00:20,  1.49s/it]\u001b[A\n",
            " 87% 90/103 [10:36<00:19,  1.47s/it]\u001b[A\n",
            " 88% 91/103 [10:37<00:17,  1.45s/it]\u001b[A\n",
            " 89% 92/103 [10:39<00:15,  1.44s/it]\u001b[A\n",
            " 90% 93/103 [10:40<00:14,  1.49s/it]\u001b[A\n",
            " 91% 94/103 [10:41<00:12,  1.42s/it]\u001b[A\n",
            " 92% 95/103 [10:43<00:12,  1.55s/it]\u001b[A\n",
            " 93% 96/103 [10:45<00:10,  1.54s/it]\u001b[A\n",
            " 94% 97/103 [10:46<00:09,  1.54s/it]\u001b[A\n",
            " 95% 98/103 [10:48<00:07,  1.52s/it]\u001b[A\n",
            " 96% 99/103 [10:49<00:05,  1.48s/it]\u001b[A\n",
            " 97% 100/103 [10:51<00:04,  1.54s/it]\u001b[A\n",
            " 98% 101/103 [10:53<00:03,  1.63s/it]\u001b[A\n",
            " 99% 102/103 [10:54<00:01,  1.59s/it]\u001b[A\n",
            "100% 103/103 [10:55<00:00,  1.33s/it]\u001b[A\n",
            "Epoch:2    | validation_loss:0.1046\n",
            "\n",
            "rouge1:0.4387| rouge2:0.2048| rougeL:0.3652| rougeLsum:0.3652\n",
            "\n",
            "======================================End Validation for Epoch: 2==================================\n",
            "\n",
            "======================================saving model for : 2==================================\n",
            "\n",
            "=============================================end training==================================\n",
            " 92% 184/200 [11:04<00:57,  3.61s/it]\n",
            "100% 103/103 [11:04<00:00,  6.46s/it]\n",
            "  0% 0/467 [00:00<?, ?it/s]\n",
            "=============================================generate pseudo label==================================\n",
            "100% 467/467 [34:47<00:00,  3.65s/it]\n",
            "========================================end generate pseudo label==================================\n",
            "number of labels generated:  937\n",
            "100% 467/467 [34:47<00:00,  4.47s/it]\n",
            "\n",
            "=============================================start training==================================\n",
            "\n",
            "Num_Epochs:3, Batch_size:8\n",
            "  0% 0/200 [00:00<?, ?it/s]\n",
            "  0% 0/103 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch:3    | Batch:0    | Gtrain_loss:0.1519| Dtrain_loss:0.1133|0.7824\n",
            "\n",
            " discrimnator prediction: 94.38%| 46.24%\n",
            " 10% 20/200 [00:52<07:45,  2.58s/it]\n",
            "Epoch:3    | Batch:20   | Gtrain_loss:0.3382| Dtrain_loss:0.2166|0.0271\n",
            "\n",
            " discrimnator prediction: 81.62%| 75.85%\n",
            " 20% 40/200 [01:47<08:01,  3.01s/it]\n",
            "Epoch:3    | Batch:40   | Gtrain_loss:0.2615| Dtrain_loss:0.3507|0.2446\n",
            "\n",
            " discrimnator prediction: 87.18%| 64.74%\n",
            " 30% 60/200 [02:44<06:21,  2.72s/it]\n",
            "Epoch:3    | Batch:60   | Gtrain_loss:0.3632| Dtrain_loss:0.1786|0.3986\n",
            "\n",
            " discrimnator prediction: 89.58%| 82.63%\n",
            " 40% 80/200 [03:40<05:36,  2.80s/it]\n",
            "Epoch:3    | Batch:80   | Gtrain_loss:0.1799| Dtrain_loss:0.4231|0.0199\n",
            "\n",
            " discrimnator prediction: 85.65%| 84.71%\n",
            " 50% 100/200 [04:35<04:30,  2.71s/it]\n",
            "Epoch:3    | Batch:100  | Gtrain_loss:0.4757| Dtrain_loss:0.0545|1.1662\n",
            "\n",
            " discrimnator prediction: 82.32%| 69.49%\n",
            " 60% 120/200 [05:27<03:28,  2.60s/it]\n",
            "Epoch:3    | Batch:120  | Gtrain_loss:0.3550| Dtrain_loss:0.1298|1.0404\n",
            "\n",
            " discrimnator prediction: 75.71%| 86.58%\n",
            " 70% 140/200 [06:22<02:34,  2.58s/it]\n",
            "Epoch:3    | Batch:140  | Gtrain_loss:0.2013| Dtrain_loss:0.0440|0.9505\n",
            "\n",
            " discrimnator prediction: 89.95%| 79.26%\n",
            " 80% 160/200 [07:13<01:42,  2.57s/it]\n",
            "Epoch:3    | Batch:160  | Gtrain_loss:0.3356| Dtrain_loss:0.1157|1.4030\n",
            "\n",
            " discrimnator prediction: 84.84%| 69.68%\n",
            " 90% 180/200 [08:08<00:54,  2.74s/it]\n",
            "Epoch:3    | Batch:180  | Gtrain_loss:0.2630| Dtrain_loss:0.4774|0.2280\n",
            "\n",
            " discrimnator prediction: 85.05%| 63.00%\n",
            " 92% 184/200 [08:19<00:42,  2.67s/it]\n",
            "======================================Start Validation for Epoch: 3==================================\n",
            "\n",
            "  1% 1/103 [08:21<14:12:22, 501.39s/it]\u001b[A\n",
            "  2% 2/103 [08:22<5:48:58, 207.31s/it] \u001b[A\n",
            "  3% 3/103 [08:24<3:09:00, 113.41s/it]\u001b[A\n",
            "  4% 4/103 [08:26<1:54:20, 69.30s/it] \u001b[A\n",
            "  5% 5/103 [08:27<1:13:11, 44.81s/it]\u001b[A\n",
            "  6% 6/103 [08:29<48:46, 30.17s/it]  \u001b[A\n",
            "  7% 7/103 [08:30<33:15, 20.79s/it]\u001b[A\n",
            "  8% 8/103 [08:32<23:29, 14.84s/it]\u001b[A\n",
            "  9% 9/103 [08:34<16:42, 10.66s/it]\u001b[A\n",
            " 10% 10/103 [08:35<12:07,  7.82s/it]\u001b[A\n",
            " 11% 11/103 [08:37<09:00,  5.88s/it]\u001b[A\n",
            " 12% 12/103 [08:38<06:49,  4.49s/it]\u001b[A\n",
            " 13% 13/103 [08:40<05:20,  3.56s/it]\u001b[A\n",
            " 14% 14/103 [08:41<04:15,  2.87s/it]\u001b[A\n",
            " 15% 15/103 [08:43<03:43,  2.54s/it]\u001b[A\n",
            " 16% 16/103 [08:44<03:13,  2.22s/it]\u001b[A\n",
            " 17% 17/103 [08:46<02:51,  1.99s/it]\u001b[A\n",
            " 17% 18/103 [08:47<02:37,  1.85s/it]\u001b[A\n",
            " 18% 19/103 [08:49<02:28,  1.77s/it]\u001b[A\n",
            " 19% 20/103 [08:50<02:19,  1.69s/it]\u001b[A\n",
            " 20% 21/103 [08:51<02:07,  1.56s/it]\u001b[A\n",
            " 21% 22/103 [08:53<02:06,  1.56s/it]\u001b[A\n",
            " 22% 23/103 [08:54<01:59,  1.49s/it]\u001b[A\n",
            " 23% 24/103 [08:56<01:57,  1.49s/it]\u001b[A\n",
            " 24% 25/103 [08:57<01:51,  1.43s/it]\u001b[A\n",
            " 25% 26/103 [08:59<01:52,  1.46s/it]\u001b[A\n",
            " 26% 27/103 [09:00<01:50,  1.46s/it]\u001b[A\n",
            " 27% 28/103 [09:02<01:56,  1.56s/it]\u001b[A\n",
            " 28% 29/103 [09:03<01:50,  1.49s/it]\u001b[A\n",
            " 29% 30/103 [09:05<01:50,  1.52s/it]\u001b[A\n",
            " 30% 31/103 [09:06<01:47,  1.49s/it]\u001b[A\n",
            " 31% 32/103 [09:08<01:47,  1.51s/it]\u001b[A\n",
            " 32% 33/103 [09:09<01:47,  1.53s/it]\u001b[A\n",
            " 33% 34/103 [09:11<01:50,  1.60s/it]\u001b[A\n",
            " 34% 35/103 [09:13<01:48,  1.59s/it]\u001b[A\n",
            " 35% 36/103 [09:14<01:40,  1.51s/it]\u001b[A\n",
            " 36% 37/103 [09:16<01:40,  1.52s/it]\u001b[A\n",
            " 37% 38/103 [09:17<01:38,  1.51s/it]\u001b[A\n",
            " 38% 39/103 [09:19<01:40,  1.57s/it]\u001b[A\n",
            " 39% 40/103 [09:20<01:40,  1.59s/it]\u001b[A\n",
            " 40% 41/103 [09:22<01:41,  1.63s/it]\u001b[A\n",
            " 41% 42/103 [09:23<01:33,  1.54s/it]\u001b[A\n",
            " 42% 43/103 [09:25<01:36,  1.61s/it]\u001b[A\n",
            " 43% 44/103 [09:26<01:28,  1.50s/it]\u001b[A\n",
            " 44% 45/103 [09:28<01:30,  1.55s/it]\u001b[A\n",
            " 45% 46/103 [09:30<01:30,  1.59s/it]\u001b[A\n",
            " 46% 47/103 [09:31<01:24,  1.51s/it]\u001b[A\n",
            " 47% 48/103 [09:33<01:27,  1.59s/it]\u001b[A\n",
            " 48% 49/103 [09:34<01:25,  1.57s/it]\u001b[A\n",
            " 49% 50/103 [09:36<01:24,  1.60s/it]\u001b[A\n",
            " 50% 51/103 [09:38<01:30,  1.74s/it]\u001b[A\n",
            " 50% 52/103 [09:40<01:23,  1.64s/it]\u001b[A\n",
            " 51% 53/103 [09:41<01:20,  1.61s/it]\u001b[A\n",
            " 52% 54/103 [09:42<01:15,  1.54s/it]\u001b[A\n",
            " 53% 55/103 [09:44<01:09,  1.45s/it]\u001b[A\n",
            " 54% 56/103 [09:45<01:10,  1.50s/it]\u001b[A\n",
            " 55% 57/103 [09:47<01:15,  1.64s/it]\u001b[A\n",
            " 56% 58/103 [09:49<01:13,  1.62s/it]\u001b[A\n",
            " 57% 59/103 [09:50<01:11,  1.62s/it]\u001b[A\n",
            " 58% 60/103 [09:52<01:08,  1.60s/it]\u001b[A\n",
            " 59% 61/103 [09:53<01:04,  1.53s/it]\u001b[A\n",
            " 60% 62/103 [09:55<01:04,  1.57s/it]\u001b[A\n",
            " 61% 63/103 [09:56<00:59,  1.48s/it]\u001b[A\n",
            " 62% 64/103 [09:58<00:55,  1.41s/it]\u001b[A\n",
            " 63% 65/103 [09:59<00:56,  1.50s/it]\u001b[A\n",
            " 64% 66/103 [10:01<00:53,  1.46s/it]\u001b[A\n",
            " 65% 67/103 [10:02<00:50,  1.41s/it]\u001b[A\n",
            " 66% 68/103 [10:03<00:50,  1.43s/it]\u001b[A\n",
            " 67% 69/103 [10:05<00:48,  1.43s/it]\u001b[A\n",
            " 68% 70/103 [10:06<00:47,  1.43s/it]\u001b[A\n",
            " 69% 71/103 [10:08<00:47,  1.49s/it]\u001b[A\n",
            " 70% 72/103 [10:09<00:45,  1.48s/it]\u001b[A\n",
            " 71% 73/103 [10:11<00:43,  1.47s/it]\u001b[A\n",
            " 72% 74/103 [10:12<00:41,  1.44s/it]\u001b[A\n",
            " 73% 75/103 [10:14<00:39,  1.41s/it]\u001b[A\n",
            " 74% 76/103 [10:15<00:37,  1.38s/it]\u001b[A\n",
            " 75% 77/103 [10:16<00:37,  1.43s/it]\u001b[A\n",
            " 76% 78/103 [10:18<00:40,  1.61s/it]\u001b[A\n",
            " 77% 79/103 [10:20<00:39,  1.63s/it]\u001b[A\n",
            " 78% 80/103 [10:21<00:35,  1.52s/it]\u001b[A\n",
            " 79% 81/103 [10:23<00:33,  1.52s/it]\u001b[A\n",
            " 80% 82/103 [10:24<00:31,  1.49s/it]\u001b[A\n",
            " 81% 83/103 [10:26<00:29,  1.47s/it]\u001b[A\n",
            " 82% 84/103 [10:27<00:28,  1.50s/it]\u001b[A\n",
            " 83% 85/103 [10:29<00:26,  1.48s/it]\u001b[A\n",
            " 83% 86/103 [10:30<00:26,  1.54s/it]\u001b[A\n",
            " 84% 87/103 [10:32<00:24,  1.51s/it]\u001b[A\n",
            " 85% 88/103 [10:33<00:23,  1.53s/it]\u001b[A\n",
            " 86% 89/103 [10:35<00:21,  1.52s/it]\u001b[A\n",
            " 87% 90/103 [10:36<00:19,  1.51s/it]\u001b[A\n",
            " 88% 91/103 [10:38<00:18,  1.50s/it]\u001b[A\n",
            " 89% 92/103 [10:40<00:17,  1.62s/it]\u001b[A\n",
            " 90% 93/103 [10:41<00:16,  1.62s/it]\u001b[A\n",
            " 91% 94/103 [10:43<00:13,  1.52s/it]\u001b[A\n",
            " 92% 95/103 [10:44<00:12,  1.58s/it]\u001b[A\n",
            " 93% 96/103 [10:46<00:10,  1.54s/it]\u001b[A\n",
            " 94% 97/103 [10:47<00:08,  1.48s/it]\u001b[A\n",
            " 95% 98/103 [10:49<00:07,  1.50s/it]\u001b[A\n",
            " 96% 99/103 [10:50<00:06,  1.57s/it]\u001b[A\n",
            " 97% 100/103 [10:52<00:05,  1.70s/it]\u001b[A\n",
            " 98% 101/103 [10:54<00:03,  1.68s/it]\u001b[A\n",
            " 99% 102/103 [10:56<00:01,  1.65s/it]\u001b[A\n",
            "100% 103/103 [10:56<00:00,  1.36s/it]\u001b[A\n",
            "Epoch:3    | validation_loss:0.1069\n",
            "\n",
            "rouge1:0.4421| rouge2:0.2097| rougeL:0.3694| rougeLsum:0.3692\n",
            "\n",
            "======================================End Validation for Epoch: 3==================================\n",
            "\n",
            "======================================saving model for : 3==================================\n",
            "\n",
            "=============================================end training==================================\n",
            " 92% 184/200 [11:05<00:57,  3.62s/it]\n",
            "100% 103/103 [11:05<00:00,  6.47s/it]\n",
            "  0% 0/467 [00:00<?, ?it/s]\n",
            "=============================================generate pseudo label==================================\n",
            "100% 467/467 [33:55<00:00,  3.38s/it]\n",
            "========================================end generate pseudo label==================================\n",
            "number of labels generated:  42\n",
            "100% 467/467 [33:55<00:00,  4.36s/it]\n",
            "\n",
            "=============================================start training==================================\n",
            "\n",
            "Num_Epochs:4, Batch_size:8\n",
            "  0% 0/11 [00:00<?, ?it/s]\n",
            "  0% 0/103 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch:4    | Batch:0    | Gtrain_loss:0.3743| Dtrain_loss:0.5377|0.1815\n",
            "\n",
            " discrimnator prediction: 70.56%| 94.38%\n",
            "100% 11/11 [00:30<00:00,  2.85s/it]\n",
            "======================================Start Validation for Epoch: 4==================================\n",
            "\n",
            "  1% 1/103 [00:32<55:01, 32.36s/it]\u001b[A\n",
            "  2% 2/103 [00:34<24:05, 14.31s/it]\u001b[A\n",
            "  3% 3/103 [00:35<14:15,  8.56s/it]\u001b[A\n",
            "  4% 4/103 [00:37<09:38,  5.84s/it]\u001b[A\n",
            "  5% 5/103 [00:38<06:58,  4.27s/it]\u001b[A\n",
            "  6% 6/103 [00:40<05:38,  3.49s/it]\u001b[A\n",
            "  7% 7/103 [00:42<04:32,  2.84s/it]\u001b[A\n",
            "  8% 8/103 [00:44<04:04,  2.58s/it]\u001b[A\n",
            "  9% 9/103 [00:45<03:30,  2.24s/it]\u001b[A\n",
            " 10% 10/103 [00:47<03:15,  2.10s/it]\u001b[A\n",
            " 11% 11/103 [00:49<03:08,  2.05s/it]\u001b[A\n",
            " 12% 12/103 [00:51<02:49,  1.86s/it]\u001b[A\n",
            " 13% 13/103 [00:52<02:42,  1.80s/it]\u001b[A\n",
            " 14% 14/103 [00:54<02:47,  1.89s/it]\u001b[A\n",
            " 15% 15/103 [00:56<02:50,  1.94s/it]\u001b[A\n",
            " 16% 16/103 [00:58<02:48,  1.94s/it]\u001b[A\n",
            " 17% 17/103 [01:00<02:42,  1.89s/it]\u001b[A\n",
            " 17% 18/103 [01:02<02:34,  1.81s/it]\u001b[A\n",
            " 18% 19/103 [01:03<02:30,  1.79s/it]\u001b[A\n",
            " 19% 20/103 [01:05<02:31,  1.82s/it]\u001b[A\n",
            " 20% 21/103 [01:07<02:18,  1.69s/it]\u001b[A\n",
            " 21% 22/103 [01:08<02:17,  1.70s/it]\u001b[A\n",
            " 22% 23/103 [01:10<02:21,  1.77s/it]\u001b[A\n",
            " 23% 24/103 [01:13<02:31,  1.91s/it]\u001b[A\n",
            " 24% 25/103 [01:14<02:20,  1.79s/it]\u001b[A\n",
            " 25% 26/103 [01:16<02:16,  1.77s/it]\u001b[A\n",
            " 26% 27/103 [01:18<02:18,  1.82s/it]\u001b[A\n",
            " 27% 28/103 [01:20<02:23,  1.91s/it]\u001b[A\n",
            " 28% 29/103 [01:22<02:14,  1.82s/it]\u001b[A\n",
            " 29% 30/103 [01:23<02:07,  1.75s/it]\u001b[A\n",
            " 30% 31/103 [01:25<02:08,  1.78s/it]\u001b[A\n",
            " 31% 32/103 [01:27<02:09,  1.82s/it]\u001b[A\n",
            " 32% 33/103 [01:29<02:10,  1.87s/it]\u001b[A\n",
            " 33% 34/103 [01:31<02:10,  1.89s/it]\u001b[A\n",
            " 34% 35/103 [01:32<02:02,  1.81s/it]\u001b[A\n",
            " 35% 36/103 [01:34<01:55,  1.72s/it]\u001b[A\n",
            " 36% 37/103 [01:36<01:55,  1.76s/it]\u001b[A\n",
            " 37% 38/103 [01:37<01:52,  1.73s/it]\u001b[A\n",
            " 38% 39/103 [01:40<02:00,  1.89s/it]\u001b[A\n",
            " 39% 40/103 [01:42<02:04,  1.98s/it]\u001b[A\n",
            " 40% 41/103 [01:44<01:59,  1.94s/it]\u001b[A\n",
            " 41% 42/103 [01:45<01:53,  1.86s/it]\u001b[A\n",
            " 42% 43/103 [01:48<01:58,  1.97s/it]\u001b[A\n",
            " 43% 44/103 [01:49<01:47,  1.82s/it]\u001b[A\n",
            " 44% 45/103 [01:51<01:48,  1.86s/it]\u001b[A\n",
            " 45% 46/103 [01:53<01:41,  1.79s/it]\u001b[A\n",
            " 46% 47/103 [01:54<01:38,  1.75s/it]\u001b[A\n",
            " 47% 48/103 [01:56<01:42,  1.86s/it]\u001b[A\n",
            " 48% 49/103 [01:58<01:38,  1.82s/it]\u001b[A\n",
            " 49% 50/103 [02:00<01:35,  1.81s/it]\u001b[A\n",
            " 50% 51/103 [02:03<01:50,  2.12s/it]\u001b[A\n",
            " 50% 52/103 [02:04<01:41,  1.99s/it]\u001b[A\n",
            " 51% 53/103 [02:06<01:35,  1.91s/it]\u001b[A\n",
            " 52% 54/103 [02:08<01:28,  1.81s/it]\u001b[A\n",
            " 53% 55/103 [02:09<01:22,  1.72s/it]\u001b[A\n",
            " 54% 56/103 [02:11<01:26,  1.84s/it]\u001b[A\n",
            " 55% 57/103 [02:13<01:27,  1.90s/it]\u001b[A\n",
            " 56% 58/103 [02:15<01:27,  1.93s/it]\u001b[A\n",
            " 57% 59/103 [02:17<01:22,  1.88s/it]\u001b[A\n",
            " 58% 60/103 [02:19<01:19,  1.85s/it]\u001b[A\n",
            " 59% 61/103 [02:20<01:11,  1.71s/it]\u001b[A\n",
            " 60% 62/103 [02:22<01:08,  1.68s/it]\u001b[A\n",
            " 61% 63/103 [02:24<01:08,  1.71s/it]\u001b[A\n",
            " 62% 64/103 [02:25<01:05,  1.67s/it]\u001b[A\n",
            " 63% 65/103 [02:28<01:09,  1.82s/it]\u001b[A\n",
            " 64% 66/103 [02:29<01:02,  1.70s/it]\u001b[A\n",
            " 65% 67/103 [02:31<00:59,  1.67s/it]\u001b[A\n",
            " 66% 68/103 [02:32<01:00,  1.72s/it]\u001b[A\n",
            " 67% 69/103 [02:34<01:00,  1.77s/it]\u001b[A\n",
            " 68% 70/103 [02:36<00:55,  1.69s/it]\u001b[A\n",
            " 69% 71/103 [02:37<00:53,  1.68s/it]\u001b[A\n",
            " 70% 72/103 [02:39<00:52,  1.68s/it]\u001b[A\n",
            " 71% 73/103 [02:41<00:49,  1.67s/it]\u001b[A\n",
            " 72% 74/103 [02:42<00:46,  1.62s/it]\u001b[A\n",
            " 73% 75/103 [02:44<00:45,  1.62s/it]\u001b[A\n",
            " 74% 76/103 [02:45<00:43,  1.60s/it]\u001b[A\n",
            " 75% 77/103 [02:47<00:43,  1.66s/it]\u001b[A\n",
            " 76% 78/103 [02:50<00:48,  1.93s/it]\u001b[A\n",
            " 77% 79/103 [02:52<00:45,  1.92s/it]\u001b[A\n",
            " 78% 80/103 [02:53<00:40,  1.78s/it]\u001b[A\n",
            " 79% 81/103 [02:55<00:40,  1.86s/it]\u001b[A\n",
            " 80% 82/103 [02:57<00:37,  1.80s/it]\u001b[A\n",
            " 81% 83/103 [02:59<00:35,  1.77s/it]\u001b[A\n",
            " 82% 84/103 [03:00<00:34,  1.81s/it]\u001b[A\n",
            " 83% 85/103 [03:02<00:31,  1.78s/it]\u001b[A\n",
            " 83% 86/103 [03:04<00:29,  1.76s/it]\u001b[A\n",
            " 84% 87/103 [03:06<00:29,  1.82s/it]\u001b[A\n",
            " 85% 88/103 [03:08<00:26,  1.79s/it]\u001b[A\n",
            " 86% 89/103 [03:10<00:25,  1.85s/it]\u001b[A\n",
            " 87% 90/103 [03:11<00:22,  1.73s/it]\u001b[A\n",
            " 88% 91/103 [03:13<00:20,  1.69s/it]\u001b[A\n",
            " 89% 92/103 [03:15<00:19,  1.78s/it]\u001b[A\n",
            " 90% 93/103 [03:16<00:17,  1.76s/it]\u001b[A\n",
            " 91% 94/103 [03:18<00:14,  1.67s/it]\u001b[A\n",
            " 92% 95/103 [03:20<00:14,  1.81s/it]\u001b[A\n",
            " 93% 96/103 [03:22<00:12,  1.80s/it]\u001b[A\n",
            " 94% 97/103 [03:23<00:10,  1.76s/it]\u001b[A\n",
            " 95% 98/103 [03:25<00:08,  1.66s/it]\u001b[A\n",
            " 96% 99/103 [03:26<00:06,  1.63s/it]\u001b[A\n",
            " 97% 100/103 [03:28<00:05,  1.77s/it]\u001b[A\n",
            " 98% 101/103 [03:30<00:03,  1.75s/it]\u001b[A\n",
            " 99% 102/103 [03:32<00:01,  1.74s/it]\u001b[A\n",
            "100% 103/103 [03:33<00:00,  1.44s/it]\u001b[A\n",
            "Epoch:4    | validation_loss:0.1081\n",
            "\n",
            "rouge1:0.4528| rouge2:0.2144| rougeL:0.3705| rougeLsum:0.3699\n",
            "\n",
            "======================================End Validation for Epoch: 4==================================\n",
            "\n",
            "======================================saving model for : 4==================================\n",
            "\n",
            "=============================================end training==================================\n",
            "100% 11/11 [03:43<00:00, 20.32s/it]\n",
            "100% 103/103 [03:43<00:00,  2.17s/it]\n",
            "  0% 0/467 [00:00<?, ?it/s]\n",
            "=============================================generate pseudo label==================================\n",
            "100% 467/467 [43:20<00:00,  4.52s/it]\n",
            "========================================end generate pseudo label==================================\n",
            "number of labels generated:  1203\n",
            "100% 467/467 [43:21<00:00,  5.57s/it]\n",
            "\n",
            "=============================================start training==================================\n",
            "\n",
            "Num_Epochs:5, Batch_size:8\n",
            "  0% 0/200 [00:00<?, ?it/s]\n",
            "  0% 0/103 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch:5    | Batch:0    | Gtrain_loss:0.1794| Dtrain_loss:0.2154|0.9373\n",
            "\n",
            " discrimnator prediction: 94.38%| 48.34%\n",
            " 10% 20/200 [00:52<07:19,  2.44s/it]\n",
            "Epoch:5    | Batch:20   | Gtrain_loss:0.2387| Dtrain_loss:0.0540|0.0303\n",
            "\n",
            " discrimnator prediction: 88.91%| 76.89%\n",
            " 20% 40/200 [01:48<07:24,  2.78s/it]\n",
            "Epoch:5    | Batch:40   | Gtrain_loss:0.2576| Dtrain_loss:0.2389|0.7681\n",
            "\n",
            " discrimnator prediction: 83.50%| 62.84%\n",
            " 30% 60/200 [02:46<06:22,  2.73s/it]\n",
            "Epoch:5    | Batch:60   | Gtrain_loss:0.3937| Dtrain_loss:0.4595|0.0380\n",
            "\n",
            " discrimnator prediction: 76.71%| 86.07%\n",
            " 40% 80/200 [03:41<05:34,  2.79s/it]\n",
            "Epoch:5    | Batch:80   | Gtrain_loss:0.1677| Dtrain_loss:0.7763|0.2250\n",
            "\n",
            " discrimnator prediction: 89.26%| 54.17%\n",
            " 50% 100/200 [04:35<04:33,  2.74s/it]\n",
            "Epoch:5    | Batch:100  | Gtrain_loss:0.1949| Dtrain_loss:0.0994|0.0625\n",
            "\n",
            " discrimnator prediction: 82.36%| 82.45%\n",
            " 60% 120/200 [05:28<03:30,  2.63s/it]\n",
            "Epoch:5    | Batch:120  | Gtrain_loss:0.2292| Dtrain_loss:0.2551|0.4296\n",
            "\n",
            " discrimnator prediction: 86.34%| 80.59%\n",
            " 70% 140/200 [06:21<02:42,  2.70s/it]\n",
            "Epoch:5    | Batch:140  | Gtrain_loss:0.2703| Dtrain_loss:1.1438|0.1780\n",
            "\n",
            " discrimnator prediction: 88.83%| 79.37%\n",
            " 80% 160/200 [07:15<01:43,  2.59s/it]\n",
            "Epoch:5    | Batch:160  | Gtrain_loss:0.3820| Dtrain_loss:0.3932|0.0765\n",
            "\n",
            " discrimnator prediction: 86.11%| 69.86%\n",
            " 90% 180/200 [08:10<00:53,  2.67s/it]\n",
            "Epoch:5    | Batch:180  | Gtrain_loss:0.2109| Dtrain_loss:0.3493|0.2433\n",
            "\n",
            " discrimnator prediction: 79.10%| 85.16%\n",
            " 92% 184/200 [08:21<00:42,  2.68s/it]\n",
            "======================================Start Validation for Epoch: 5==================================\n",
            "\n",
            "  1% 1/103 [08:23<14:15:16, 503.10s/it]\u001b[A\n",
            "  2% 2/103 [08:24<5:50:18, 208.10s/it] \u001b[A\n",
            "  3% 3/103 [08:26<3:09:44, 113.84s/it]\u001b[A\n",
            "  4% 4/103 [08:27<1:54:38, 69.48s/it] \u001b[A\n",
            "  5% 5/103 [08:29<1:13:21, 44.91s/it]\u001b[A\n",
            "  6% 6/103 [08:30<48:53, 30.24s/it]  \u001b[A\n",
            "  7% 7/103 [08:32<33:19, 20.83s/it]\u001b[A\n",
            "  8% 8/103 [08:34<23:23, 14.77s/it]\u001b[A\n",
            "  9% 9/103 [08:35<16:41, 10.65s/it]\u001b[A\n",
            " 10% 10/103 [08:37<12:07,  7.82s/it]\u001b[A\n",
            " 11% 11/103 [08:38<09:02,  5.89s/it]\u001b[A\n",
            " 12% 12/103 [08:40<06:48,  4.49s/it]\u001b[A\n",
            " 13% 13/103 [08:41<05:19,  3.55s/it]\u001b[A\n",
            " 14% 14/103 [08:42<04:18,  2.90s/it]\u001b[A\n",
            " 15% 15/103 [08:44<03:47,  2.59s/it]\u001b[A\n",
            " 16% 16/103 [08:46<03:16,  2.25s/it]\u001b[A\n",
            " 17% 17/103 [08:47<02:49,  1.97s/it]\u001b[A\n",
            " 17% 18/103 [08:49<02:36,  1.84s/it]\u001b[A\n",
            " 18% 19/103 [08:50<02:26,  1.75s/it]\u001b[A\n",
            " 19% 20/103 [08:52<02:22,  1.72s/it]\u001b[A\n",
            " 20% 21/103 [08:53<02:08,  1.57s/it]\u001b[A\n",
            " 21% 22/103 [08:55<02:12,  1.63s/it]\u001b[A\n",
            " 22% 23/103 [08:57<02:14,  1.68s/it]\u001b[A\n",
            " 23% 24/103 [08:58<02:12,  1.68s/it]\u001b[A\n",
            " 24% 25/103 [09:00<02:04,  1.60s/it]\u001b[A\n",
            " 25% 26/103 [09:01<02:03,  1.60s/it]\u001b[A\n",
            " 26% 27/103 [09:03<01:57,  1.55s/it]\u001b[A\n",
            " 27% 28/103 [09:05<02:21,  1.89s/it]\u001b[A\n",
            " 28% 29/103 [09:07<02:09,  1.76s/it]\u001b[A\n",
            " 29% 30/103 [09:08<02:05,  1.72s/it]\u001b[A\n",
            " 30% 31/103 [09:10<02:02,  1.70s/it]\u001b[A\n",
            " 31% 32/103 [09:12<01:56,  1.64s/it]\u001b[A\n",
            " 32% 33/103 [09:13<01:52,  1.60s/it]\u001b[A\n",
            " 33% 34/103 [09:15<01:56,  1.69s/it]\u001b[A\n",
            " 34% 35/103 [09:16<01:49,  1.62s/it]\u001b[A\n",
            " 35% 36/103 [09:18<01:45,  1.57s/it]\u001b[A\n",
            " 36% 37/103 [09:20<01:48,  1.65s/it]\u001b[A\n",
            " 37% 38/103 [09:21<01:42,  1.57s/it]\u001b[A\n",
            " 38% 39/103 [09:23<01:48,  1.70s/it]\u001b[A\n",
            " 39% 40/103 [09:25<01:50,  1.76s/it]\u001b[A\n",
            " 40% 41/103 [09:27<01:44,  1.69s/it]\u001b[A\n",
            " 41% 42/103 [09:28<01:37,  1.61s/it]\u001b[A\n",
            " 42% 43/103 [09:30<01:36,  1.61s/it]\u001b[A\n",
            " 43% 44/103 [09:31<01:26,  1.47s/it]\u001b[A\n",
            " 44% 45/103 [09:32<01:26,  1.49s/it]\u001b[A\n",
            " 45% 46/103 [09:34<01:26,  1.52s/it]\u001b[A\n",
            " 46% 47/103 [09:35<01:26,  1.54s/it]\u001b[A\n",
            " 47% 48/103 [09:38<01:33,  1.70s/it]\u001b[A\n",
            " 48% 49/103 [09:39<01:27,  1.61s/it]\u001b[A\n",
            " 49% 50/103 [09:41<01:26,  1.63s/it]\u001b[A\n",
            " 50% 51/103 [09:42<01:27,  1.68s/it]\u001b[A\n",
            " 50% 52/103 [09:44<01:22,  1.62s/it]\u001b[A\n",
            " 51% 53/103 [09:45<01:18,  1.57s/it]\u001b[A\n",
            " 52% 54/103 [09:47<01:16,  1.56s/it]\u001b[A\n",
            " 53% 55/103 [09:48<01:14,  1.55s/it]\u001b[A\n",
            " 54% 56/103 [09:50<01:12,  1.54s/it]\u001b[A\n",
            " 55% 57/103 [09:52<01:14,  1.63s/it]\u001b[A\n",
            " 56% 58/103 [09:53<01:13,  1.63s/it]\u001b[A\n",
            " 57% 59/103 [09:55<01:12,  1.65s/it]\u001b[A\n",
            " 58% 60/103 [09:57<01:11,  1.66s/it]\u001b[A\n",
            " 59% 61/103 [09:58<01:05,  1.55s/it]\u001b[A\n",
            " 60% 62/103 [10:00<01:06,  1.63s/it]\u001b[A\n",
            " 61% 63/103 [10:01<00:59,  1.50s/it]\u001b[A\n",
            " 62% 64/103 [10:02<00:57,  1.46s/it]\u001b[A\n",
            " 63% 65/103 [10:04<01:00,  1.59s/it]\u001b[A\n",
            " 64% 66/103 [10:06<00:56,  1.52s/it]\u001b[A\n",
            " 65% 67/103 [10:07<00:53,  1.48s/it]\u001b[A\n",
            " 66% 68/103 [10:09<00:53,  1.52s/it]\u001b[A\n",
            " 67% 69/103 [10:10<00:50,  1.49s/it]\u001b[A\n",
            " 68% 70/103 [10:12<00:48,  1.48s/it]\u001b[A\n",
            " 69% 71/103 [10:13<00:47,  1.49s/it]\u001b[A\n",
            " 70% 72/103 [10:15<00:46,  1.49s/it]\u001b[A\n",
            " 71% 73/103 [10:16<00:43,  1.45s/it]\u001b[A\n",
            " 72% 74/103 [10:17<00:42,  1.47s/it]\u001b[A\n",
            " 73% 75/103 [10:19<00:41,  1.48s/it]\u001b[A\n",
            " 74% 76/103 [10:21<00:40,  1.52s/it]\u001b[A\n",
            " 75% 77/103 [10:22<00:39,  1.53s/it]\u001b[A\n",
            " 76% 78/103 [10:24<00:41,  1.64s/it]\u001b[A\n",
            " 77% 79/103 [10:26<00:39,  1.63s/it]\u001b[A\n",
            " 78% 80/103 [10:27<00:35,  1.53s/it]\u001b[A\n",
            " 79% 81/103 [10:28<00:32,  1.50s/it]\u001b[A\n",
            " 80% 82/103 [10:30<00:30,  1.45s/it]\u001b[A\n",
            " 81% 83/103 [10:31<00:30,  1.50s/it]\u001b[A\n",
            " 82% 84/103 [10:33<00:29,  1.55s/it]\u001b[A\n",
            " 83% 85/103 [10:35<00:28,  1.57s/it]\u001b[A\n",
            " 83% 86/103 [10:36<00:27,  1.60s/it]\u001b[A\n",
            " 84% 87/103 [10:38<00:26,  1.67s/it]\u001b[A\n",
            " 85% 88/103 [10:40<00:25,  1.69s/it]\u001b[A\n",
            " 86% 89/103 [10:41<00:22,  1.61s/it]\u001b[A\n",
            " 87% 90/103 [10:43<00:20,  1.61s/it]\u001b[A\n",
            " 88% 91/103 [10:44<00:19,  1.59s/it]\u001b[A\n",
            " 89% 92/103 [10:46<00:17,  1.55s/it]\u001b[A\n",
            " 90% 93/103 [10:48<00:15,  1.60s/it]\u001b[A\n",
            " 91% 94/103 [10:49<00:13,  1.52s/it]\u001b[A\n",
            " 92% 95/103 [10:51<00:12,  1.55s/it]\u001b[A\n",
            " 93% 96/103 [10:52<00:10,  1.57s/it]\u001b[A\n",
            " 94% 97/103 [10:54<00:09,  1.53s/it]\u001b[A\n",
            " 95% 98/103 [10:55<00:07,  1.52s/it]\u001b[A\n",
            " 96% 99/103 [10:57<00:06,  1.53s/it]\u001b[A\n",
            " 97% 100/103 [10:58<00:04,  1.62s/it]\u001b[A\n",
            " 98% 101/103 [11:00<00:03,  1.65s/it]\u001b[A\n",
            " 99% 102/103 [11:02<00:01,  1.69s/it]\u001b[A\n",
            "100% 103/103 [11:03<00:00,  1.39s/it]\u001b[A\n",
            "Epoch:5    | validation_loss:0.1090\n",
            "\n",
            "rouge1:0.4450| rouge2:0.2091| rougeL:0.3676| rougeLsum:0.3677\n",
            "\n",
            "======================================End Validation for Epoch: 5==================================\n",
            "\n",
            "======================================saving model for : 5==================================\n",
            "\n",
            "=============================================end training==================================\n",
            " 92% 184/200 [11:11<00:58,  3.65s/it]\n",
            "100% 103/103 [11:11<00:00,  6.52s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -o evaluate -g '/content/drive/MyDrive/SEMI-supervise_project/SaveModel/lora_bartGAN_G_epoch4_8_pesudo.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqWELTd8QovG",
        "outputId": "a0764da6-59d9-4290-dd30-52fcc4a4ac2d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02 04:15:06.174686: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764648906.196353  169731 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764648906.202690  169731 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764648906.218868  169731 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764648906.218898  169731 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764648906.218900  169731 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764648906.218903  169731 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            " validation_loss:0.1081\n",
            "\n",
            "rouge1:0.4421| rouge2:0.1996| rougeL:0.3624| rougeLsum:0.3623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -o evaluate -g '/content/drive/MyDrive/SEMI-supervise_project/SaveModel/lora_bartGAN_G_epoch5_8_pesudo.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UixFUgDfSXTb",
        "outputId": "abeee26e-bb78-4052-d673-3a1337fc4bb0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02 04:20:04.177342: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764649204.198007  171049 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764649204.204351  171049 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764649204.220369  171049 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764649204.220394  171049 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764649204.220396  171049 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764649204.220399  171049 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            " validation_loss:0.1084\n",
            "\n",
            "rouge1:0.4236| rouge2:0.1885| rougeL:0.3520| rougeLsum:0.3517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -o evaluate -g '/content/drive/MyDrive/SEMI-supervise_project/SaveModel/lora_bartGAN_G_epoch3_8_pesudo.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuwAmWvMSktu",
        "outputId": "b30150ba-726c-49b4-a05f-56a39dd7c44e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02 04:23:11.945695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764649391.965673  171887 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764649391.971860  171887 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764649391.987240  171887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764649391.987274  171887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764649391.987277  171887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764649391.987279  171887 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            " validation_loss:0.1067\n",
            "\n",
            "rouge1:0.4183| rouge2:0.1843| rougeL:0.3500| rougeLsum:0.3497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -o evaluate -g '/content/drive/MyDrive/SEMI-supervise_project/SaveModel/lora_bartGAN_G_epoch2_8_pesudo.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGVlIU0USmfs",
        "outputId": "1b42f803-e0b3-4763-918e-c900b2663487"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02 04:26:21.605614: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764649581.627551  172731 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764649581.634034  172731 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764649581.649863  172731 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764649581.649891  172731 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764649581.649894  172731 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764649581.649897  172731 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            " validation_loss:0.1042\n",
            "\n",
            "rouge1:0.4277| rouge2:0.1906| rougeL:0.3564| rougeLsum:0.3566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -o evaluate -g '/content/drive/MyDrive/SEMI-supervise_project/SaveModel/lora_bartGAN_G_epoch1_8_pesudo.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfMPYEjHSomY",
        "outputId": "3e6a66a3-6678-4cc0-a3b8-a81629b65ec9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02 04:29:33.809536: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764649773.830236  173586 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764649773.836295  173586 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764649773.851871  173586 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764649773.851896  173586 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764649773.851899  173586 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764649773.851901  173586 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            " validation_loss:0.1031\n",
            "\n",
            "rouge1:0.4146| rouge2:0.1870| rougeL:0.3500| rougeLsum:0.3500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -o evaluate -g '/content/drive/MyDrive/SEMI-supervise_project/SaveModel/lora_bartGAN_G_epoch8_8_fine_tune.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBqsuF1iSuVT",
        "outputId": "480f136b-7d6d-4042-cf78-9c2c2aa21783"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02 04:32:42.537305: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764649962.558015  174417 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764649962.564551  174417 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764649962.580452  174417 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764649962.580478  174417 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764649962.580481  174417 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764649962.580483  174417 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            " validation_loss:0.1012\n",
            "\n",
            "rouge1:0.4180| rouge2:0.1863| rougeL:0.3502| rougeLsum:0.3501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -o evaluate -g '/content/drive/MyDrive/SEMI-supervise_project/SaveModel/lora_bartGAN_G_epoch7_8_fine_tune.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZSFE75yS0pU",
        "outputId": "0ff55227-2bda-4ea3-82f9-ada17bb19153"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02 04:35:49.524749: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764650149.546184  175235 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764650149.552651  175235 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764650149.569101  175235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764650149.569129  175235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764650149.569131  175235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764650149.569134  175235 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            " validation_loss:0.1011\n",
            "\n",
            "rouge1:0.4251| rouge2:0.1870| rougeL:0.3517| rougeLsum:0.3518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -o evaluate -g '/content/drive/MyDrive/SEMI-supervise_project/SaveModel/lora_bartGAN_G_epoch6_8_fine_tune.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3aSGIVYS4Ay",
        "outputId": "7fe7b1ed-6f11-4e4b-9c64-125bcec96489"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02 04:39:01.006996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764650341.027290  176096 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764650341.033501  176096 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764650341.049370  176096 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764650341.049395  176096 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764650341.049399  176096 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764650341.049402  176096 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            " validation_loss:0.1024\n",
            "\n",
            "rouge1:0.4186| rouge2:0.1824| rougeL:0.3464| rougeLsum:0.3461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -o evaluate -g '/content/drive/MyDrive/SEMI-supervise_project/SaveModel/lora_bartGAN_G_epoch5_8_fine_tune.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2L-e4-bS6aZ",
        "outputId": "cb31c4a4-6b1e-40cb-d298-11858e64a0e2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02 04:42:11.392798: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764650531.415100  176951 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764650531.421837  176951 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764650531.438391  176951 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764650531.438422  176951 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764650531.438426  176951 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764650531.438428  176951 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            " validation_loss:0.1012\n",
            "\n",
            "rouge1:0.4180| rouge2:0.1863| rougeL:0.3502| rougeLsum:0.3501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -o evaluate -g '/content/drive/MyDrive/SEMI-supervise_project/SaveModel/lora_bartGAN_G_epoch9_8_fine_tune.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKJOBHcGYoeY",
        "outputId": "7b43bdfa-e22f-4585-d958-112e65d11f6e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-02 04:47:20.878248: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764650840.899309  178313 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764650840.905695  178313 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764650840.921856  178313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764650840.921882  178313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764650840.921884  178313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764650840.921887  178313 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Some weights of the model checkpoint at vblagoje/bert-english-uncased-finetuned-pos were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            " validation_loss:0.1009\n",
            "\n",
            "rouge1:0.4262| rouge2:0.1934| rougeL:0.3531| rougeLsum:0.3530\n"
          ]
        }
      ]
    }
  ]
}